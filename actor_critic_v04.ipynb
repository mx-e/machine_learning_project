{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_sokoban\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "\n",
    "import queue\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "if not os.path.exists(\"model\"):\n",
    "    os.mkdir(\"model\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='tiny_rgb_array').transpose(2, 0, 1)[0]\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    screen_height, screen_width = screen.shape\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen).unsqueeze(0)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return screen.unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "#env.reset()\n",
    "#plt.figure()\n",
    "#plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "          # interpolation='none')\n",
    "#plt.title('Example extracted screen')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 7, 7])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('Sokoban-small-v1')\n",
    "env.reset()\n",
    "get_screen().size()\n",
    "#env.render(mode='tiny_rgb_array').transpose((2, 0, 1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w):\n",
    "        super(NN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        #self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1)\n",
    "        #self.bn3 = nn.BatchNorm2d(32)\n",
    "       \n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        #def conv2d_size_out(size, kernel_size = 3, stride = 1):\n",
    "         #   return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        #convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        #convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        #linear_input_size = convw * convh * 32\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(3*3*32, 3*3*32)\n",
    "        \n",
    "        self.fc2_val = nn.Linear(3*3*32, 1)\n",
    "        \n",
    "        self.fc3_pol = nn.Linear(3*3*32, 9)\n",
    "        self.fc4_pol_softmax = nn.Softmax()\n",
    "\n",
    "    \n",
    "        \n",
    "       \n",
    "        \n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x, val_bool = False):\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.fc1(x.view(x.size(0), -1)))\n",
    "        \n",
    "        # output value             \n",
    "        x_val = F.relu(self.fc2_val(x.view(x.size(0), -1)))\n",
    "        \n",
    "        # output policy         \n",
    "        x_pol = self.fc3_pol(x.view(x.size(0), -1))\n",
    "        x_pol = self.fc4_pol_softmax(x_pol.view(x_pol.size(0), -1))           \n",
    "    \n",
    "        \n",
    "        return (x_val, x_pol)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(t_max, main_model, global_t):\n",
    "\n",
    "    thread = gym.make('Sokoban-small-v1') \n",
    "\n",
    "\n",
    "    # sync train model copy with global train model\n",
    "    #train_model = main_model\n",
    "\n",
    "\n",
    "    # thread-step-counter t = 0\n",
    "    t = 0\n",
    "\n",
    "\n",
    "    #pol_netlist[counter] = net\n",
    "\n",
    "    # reset policy and val gradients\n",
    "    optimizer.zero_grad() \n",
    "\n",
    "    # tstart = t\n",
    "    # get state s_t\n",
    "    thread.reset()\n",
    "\n",
    "    r = []\n",
    "    s = []\n",
    "    a = []\n",
    "\n",
    "    # while t < t_max and game_not_finished\n",
    "    game_finished = False\n",
    "    \n",
    "    \n",
    "    while t < t_max and not game_finished:\n",
    "\n",
    "        # perform a_t with policy net\n",
    "        #print((torch.from_numpy(thread.render('tiny_rgb_array')[:,:,0])))\n",
    "        s.append(get_screen())\n",
    "        #print(s[t])\n",
    "        a.append(select_action(s[t]))\n",
    "        _, reward, game_finished,_ = thread.step(a[t]) # mapping actions + 1 \n",
    "\n",
    "        r.append(reward)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    # R = 0 if game_not_finished == True, else R = value(s_t)\n",
    "\n",
    "    if (game_finished == True):\n",
    "        R = 0\n",
    "    else: \n",
    "        \n",
    "        R = main_model(s[t])[0].view(1, 1).item()\n",
    "        \n",
    "        t = t + 1\n",
    "        \n",
    "    for j in range(t-1, -1, -1):\n",
    "        R = r[j] + gamma*R\n",
    "        val = main_model(s[j])[0]\n",
    "    \n",
    "        # PROBLEM: FUNKTIONIERT DAS BACKPROP RICHTIG, wegen verschiedenen branches\n",
    "        loss = numpy.log(main_model(s[j])[1][a[j]]*(R-val))\n",
    "        loss.backwards()\n",
    "        optimizer.step()\n",
    "        loss = np.square(val-R)\n",
    "        loss.backwards()\n",
    "        optimizer.step()\n",
    "    \n",
    "        actual_pol = main_model(s[j])[1][a[j]-1]\n",
    "        criterion1 = nn.L1Loss()\n",
    "        loss1 = criterion1(actual_pol*val, actual_pol*R)\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        criterion2 = nn.MSEloss()\n",
    "        loss2 = criterion2(val, R)\n",
    "        loss2.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    print(\"actions:\",a,\"rewards:\",r)    \n",
    "    # perform asynchronous updates of policy and value net using the gradients\n",
    "    \n",
    "    print(\"global training step\", global_t, \"finished\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(episodes):\n",
    "    \n",
    "    env = gym.make('Sokoban-small-v1')\n",
    "    env.render('tiny_rgb_array')[:,:,0]\n",
    "    \n",
    "    iteration_count = 0\n",
    "    reward_sum = 0\n",
    "    episode_len_sum = 0\n",
    "    for i_episode in range(episodes):\n",
    "        # Initialize the environment and state\n",
    "        env.reset()\n",
    "        last_screen = get_screen()\n",
    "        current_screen = get_screen()\n",
    "        for t in count():\n",
    "            iteration_count += 1\n",
    "            #current_screen = get_screen()\n",
    "            # Select and perform an action\n",
    "            action = main_model(get_screen(), val_bool = False)[1].max(1)[1].view(1, 1).item()\n",
    "            \n",
    "            _, reward, done, _ = env.step(action+1)\n",
    "            reward_sum += reward\n",
    "            if done:\n",
    "                episode_len_sum += t\n",
    "                break\n",
    "            if iteration_count > 50:\n",
    "                break\n",
    "    env.close()\n",
    "    average_reward = reward_sum / iteration_count\n",
    "    average_ep_len = episode_len_sum / episodes\n",
    "    print(average_reward, average_ep_len)\n",
    "    return average_reward, average_ep_len\n",
    "    \n",
    "#test_model(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS_START = 0.99\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 20000\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return main_model(state)[1].max(1)[1].view(1, 1).item()\n",
    "    else:\n",
    "        return env.action_space.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "\n",
    "global_tmax = 100\n",
    "t_max = 30\n",
    "game_not_finished = True # vorläufig, eig soll das das gym zurückgeben\n",
    "gamma = 0.99# discont rate \n",
    "\n",
    "# INITIALIZATION\n",
    "env = gym.make('Sokoban-small-v1')\n",
    "\n",
    "main_model = NN(screen_height, screen_width).to(device)\n",
    "\n",
    "optimizer = optim.RMSprop(main_model.parameters())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [2, 8, 7, 1, 7, 7, 5, 5, 0, 2, 1, 6, 2, 7, 6, 4, 4, 7, 0, 3, 1, 6, 6, 8, 5, 4, 0, 6, 2, 7, 0, 2, 8, 3, 3, 4, 0, 1, 2, 5, 2, 1, 2, 8, 2, 3, 0, 3, 2, 0, 8, 8, 0, 2, 6, 4, 4, 4, 7, 0, 4, 2, 1, 5, 3, 0, 4, 8, 6, 1, 3, 6, 5, 7, 0, 1, 4, 0, 5, 1, 4, 7, 2, 7, 0, 5, 3, 6, 1, 1, 1, 4, 0, 4, 5, 5, 0, 7, 8, 8, 1, 4, 2, 3, 4, 6, 5, 5, 2, 4, 2, 6, 2, 5, 3, 3, 5, 6, 0, 3, 3, 5, 8, 2, 2, 6, 6, 7, 2, 6, 6, 7, 0, 7, 0, 8, 4, 8, 5, 8, 6, 7, 7, 1, 7, 8, 4, 2, 2, 6, 8, 0, 0, 5, 4, 8, 0, 2, 4, 3, 8, 2, 8, 2, 3, 0, 1, 2, 6, 5, 6, 8, 3, 0, 4, 1, 0, 3, 8, 7, 1, 4, 1, 8, 2, 1, 7, 5, 7, 7, 1, 0, 8, 3, 4, 8, 0, 1, 6, 3] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 0 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n",
      "-0.09999999999999987 0.0\n",
      "actions: [3, 5, 0, 4, 2, 1, 4, 7, 6, 1, 2, 0, 7, 2, 5, 6, 7, 8, 3, 8, 3, 5, 5, 2, 7, 4, 3, 7, 1, 6, 4, 7, 5, 8, 2, 3, 1, 3, 1, 4, 6, 4, 7, 4, 5, 2, 2, 4, 8, 1, 8, 0, 2, 6, 3, 8, 4, 2, 1, 8, 8, 2, 5, 5, 2, 8, 6, 2, 6, 1, 6, 8, 2, 3, 5, 4, 8, 4, 7, 7, 1, 0, 0, 2, 2, 6, 4, 0, 7, 6, 2, 5, 7, 2, 4, 5, 8, 0, 3, 1, 3, 2, 6, 0, 1, 8, 5, 1, 0, 8, 1, 3, 4, 3, 8, 2, 0, 7, 5, 2, 3, 5, 5, 7, 8, 4, 1, 5, 3, 4, 4, 3, 6, 6, 2, 5, 4, 1, 2, 5, 7, 6, 1, 1, 0, 6, 3, 5, 8, 3, 6, 7, 4, 5, 8, 8, 2, 8, 7, 2, 5, 1, 0, 4, 8, 5, 7, 0, 4, 1, 2, 2, 1, 8, 2, 6, 1, 8, 2, 8, 6, 8, 2, 3, 1, 2, 0, 2, 0, 6, 8, 0, 8, 8, 8, 3, 7, 7, 4, 1] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 1 finished\n",
      "actions: [5, 7, 8, 5, 6, 6, 5, 7, 3, 4, 4, 1, 5, 6, 1, 7, 0, 4, 7, 8, 2, 2, 2, 7, 0, 4, 2, 1, 4, 6, 2, 6, 1, 0, 1, 3, 8, 4, 7, 6, 2, 2, 0, 2, 4, 2, 1, 2, 6, 0, 6, 0, 6, 2, 0, 4, 1, 0, 6, 6, 1, 4, 1, 3, 5, 0, 6, 4, 4, 1, 3, 5, 8, 0, 4, 1, 6, 6, 0, 8, 2, 1, 0, 2, 8, 2, 2, 6, 5, 8, 4, 1, 1, 4, 6, 0, 4, 1, 8, 0, 2, 7, 6, 3, 4, 1, 0, 6, 1, 5, 4, 1, 4, 0, 7, 0, 5, 6, 2, 8, 2, 6, 2, 4, 3, 7, 4, 0, 8, 6, 0, 8, 0, 1, 7, 5, 3, 8, 4, 8, 5, 2, 4, 7, 4, 0, 2, 2, 4, 1, 8, 7, 4, 7, 5, 0, 0, 0, 3, 2, 6, 6, 1, 2, 0, 8, 3, 7, 1, 1, 4, 5, 2, 5, 0, 3, 7, 3, 8, 4, 5, 5, 7, 2, 0, 2, 3, 6, 6, 6, 6, 5, 2, 2, 3, 0, 8, 1, 2, 1] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 2 finished\n",
      "actions: [8, 3, 3, 5, 4, 5, 8, 5, 2, 8, 3, 2, 3, 1, 7, 0, 5, 3, 1, 5, 6, 4, 6, 8, 0, 6, 4, 7, 0, 1, 5, 0, 8, 1, 2, 2, 2, 1, 0, 0, 3, 1, 0, 1, 4, 3, 8, 2, 2, 0, 3, 8, 1, 3, 1, 3, 2, 5, 8, 1, 4, 3, 3, 7, 6, 4, 6, 8, 8, 6, 1, 6, 8, 6, 1, 6, 5, 2, 1, 1, 7, 2, 2, 2, 2, 6, 2, 3, 3, 8, 5, 8, 0, 7, 6, 4, 0, 8, 3, 4, 3, 0, 0, 6, 2, 1, 7, 8, 5, 4, 1, 5, 5, 3, 0, 5, 8, 1, 7, 6, 3, 7, 0, 7, 2, 5, 0, 5, 0, 2, 6, 1, 2, 5, 8, 0, 6, 1, 2, 7, 2, 5, 8, 4, 6, 1, 2, 2, 2, 2, 3, 5, 2, 6, 2, 7, 1, 1, 4, 7, 6, 7, 4, 6, 6, 6, 3, 3, 2, 3, 0, 8, 2, 3, 8, 2, 3, 5, 2, 5, 8, 2, 2, 8, 8, 0, 2, 5, 1, 2, 6, 8, 5, 5, 8, 8, 8, 2, 4, 7] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 3 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [6, 7, 8, 1, 0, 7, 3, 2, 1, 7, 4, 7, 1, 8, 5, 7, 6, 6, 2, 6, 7, 8, 3, 3, 1, 1, 7, 2, 0, 3, 3, 0, 4, 2, 7, 4, 2, 1, 5, 2, 7, 7, 5, 2, 5, 8, 6, 5, 0, 7, 7, 0, 7, 2, 4, 4, 1, 5, 3, 2, 0, 2, 8, 2, 7, 3, 5, 2, 0, 6, 2, 7, 0, 1, 8, 2, 4, 7, 8, 2, 5, 4, 3, 3, 3, 0, 7, 2, 0, 4, 8, 1, 2, 6, 4, 4, 3, 5, 6, 3, 1, 6, 6, 5, 2, 1, 8, 4, 1, 2, 4, 5, 0, 2, 1, 6, 6, 5, 4, 3, 3, 0, 7, 8, 3, 4, 6, 3, 5, 1, 8, 5, 6, 8, 7, 2, 1, 4, 1, 6, 2, 8, 5, 1, 6, 3, 2, 0, 3, 4, 5, 8, 2, 1, 3, 0, 5, 4, 5, 7, 3, 2, 6, 6, 0, 1, 6, 7, 8, 3, 3, 1, 1, 8, 0, 2, 0, 1, 2, 3, 1, 4, 2, 5, 3, 2, 7, 0, 1, 7, 5, 3, 2, 6, 1, 4, 2, 5, 0, 1] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 4 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n",
      "actions: [6, 2, 4, 5, 4, 0, 2, 6, 7, 6, 3, 3, 5, 0, 1, 2, 7, 2, 4, 0, 5, 4, 2, 6, 4, 7, 8, 0, 8, 3, 4, 8, 5, 0, 6, 4, 1, 3, 4, 7, 5, 5, 3, 2, 1, 4, 4, 2, 3, 1, 5, 5, 0, 2, 3, 7, 0, 8, 1, 2, 8, 3, 1, 6, 8, 5, 7, 8, 4, 7, 7, 8, 5, 2, 7, 0, 5, 3, 3, 3, 7, 4, 4, 0, 4, 2, 7, 1, 2, 1, 3, 4, 3, 6, 0, 4, 3, 6, 5, 3, 6, 6, 2, 5, 1, 7, 5, 2, 1, 4, 5, 5, 2, 1, 0, 0, 3, 0, 5, 5, 4, 8, 6, 7, 8, 1, 7, 5, 2, 6, 1, 7, 1, 7, 2, 3, 7, 7, 4, 7, 2, 2, 2, 6, 3, 7, 3, 3, 1, 2, 2, 4, 0, 3, 4, 2, 8, 4, 6, 6, 1, 5, 7, 6, 0, 8, 4, 6, 5, 3, 6, 0, 4, 4, 2, 8, 5, 5, 6, 8, 1, 7, 6, 7, 5, 1, 7, 8, 6, 6, 2, 8, 4, 0, 6, 0, 7, 2, 8, 0] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 5 finished\n",
      "actions: [5, 6, 2, 5, 0, 7, 4, 4, 2, 6, 7, 1, 6, 1, 7, 0, 1, 1, 7, 6, 0, 3, 1, 1, 1, 5, 2, 0, 1, 8, 8, 8, 1, 5, 7, 2, 5, 4, 3, 3, 8, 2, 7, 1, 6, 2, 7, 2, 6, 1, 7, 4, 2, 3, 7, 5, 1, 3, 7, 0, 8, 2, 0, 8, 3, 5, 2, 7, 2, 4, 4, 3, 0, 5, 3, 0, 0, 1, 6, 2, 3, 0, 0, 7, 1, 1, 5, 4, 2, 0, 1, 0, 3, 8, 1, 2, 7, 7, 5, 1, 1, 6, 3, 4, 0, 4, 7, 2, 2, 2, 1, 0, 0, 2, 0, 7, 7, 5, 6, 2, 8, 3, 1, 5, 6, 7, 2, 6, 0, 0, 1, 6, 1, 6, 0, 8, 8, 6, 3, 2, 8, 1, 7, 3, 4, 4, 2, 2, 5, 2, 4, 2, 6, 6, 2, 6, 5, 0, 5, 1, 2, 5, 5, 5, 5, 4, 7, 4, 2, 2, 6, 4, 1, 4, 4, 4, 5, 1, 6, 7, 7, 8, 8, 1, 7, 1, 2, 5, 0, 4, 4, 7, 7, 2, 7, 7, 1, 6, 5, 6] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 6 finished\n",
      "actions: [4, 0, 3, 6, 1, 5, 6, 7, 8, 2, 6, 2, 0, 3, 3, 1, 8, 8, 5, 7, 5, 5, 8, 3, 4, 5, 4, 8, 0, 2, 4, 2, 8, 7, 5, 2, 6, 5, 5, 4, 6, 5, 3, 8, 8, 1, 8, 6, 1, 6, 2, 4, 6, 3, 6, 6, 5, 5, 8, 2, 2, 7, 3, 0, 0, 2, 7, 8, 3, 8, 7, 6, 2, 7, 2, 6, 3, 8, 2, 6, 5, 6, 2, 7, 7, 2, 5, 2, 1, 6, 0, 2, 6, 3, 2, 8, 3, 3, 3, 5, 4, 2, 4, 2, 2, 7, 8, 4, 8, 5, 0, 7, 3, 2, 6, 6, 4, 8, 6, 3, 7, 6, 5, 0, 2, 1, 5, 8, 2, 6, 7, 7, 6, 1, 7, 5, 8, 3, 8, 1, 6, 3, 0, 4, 1, 5, 3, 2, 0, 2, 2, 0, 2, 8, 1, 7, 4, 8, 3, 2, 1, 1, 6, 1, 5, 2, 2, 3, 2, 4, 5, 4, 0, 3, 0, 4, 0, 0, 3, 2, 7, 7, 7, 0, 2, 0, 2, 4, 8, 3, 5, 1, 7, 7, 2, 7, 4, 3, 4, 4] rewards: [-0.1, 0.9, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 7 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [2, 7, 2, 7, 7, 5, 4, 6, 5, 2, 6, 8, 6, 0, 1, 0, 2, 0, 3, 3, 4, 0, 5, 2, 5, 6, 4, 1, 5, 6, 0, 5, 3, 3, 8, 7, 1, 2, 0, 3, 2, 4, 1, 3, 2, 7, 7, 7, 5, 6, 0, 7, 6, 2, 3, 4, 5, 3, 2, 2, 2, 8, 5, 2, 5, 7, 0, 4, 3, 3, 0, 7, 2, 2, 5, 3, 4, 3, 7, 3, 1, 4, 5, 7, 2, 6, 2, 6, 0, 0, 4, 3, 3, 2, 3, 2, 8, 1, 4, 5, 0, 1, 5, 7, 0, 4, 0, 7, 6, 4, 5, 2, 4, 7, 6, 4, 3, 0, 7, 4, 2, 7, 2, 1, 7, 4, 2, 6, 3, 2, 1, 8, 5, 7, 2, 4, 8, 7, 6, 8, 5, 4, 3, 8, 7, 2, 1, 5, 7, 3, 3, 5, 2, 2, 2, 7, 8, 3, 0, 0, 3, 8, 5, 4, 6, 8, 2, 0, 5, 4, 2, 3, 7, 3, 8, 5, 1, 5, 0, 1, 7, 2, 5, 8, 5, 1, 4, 3, 3, 5, 3, 2, 2, 2, 4, 4, 2, 7, 6, 8] rewards: [-0.1, 0.9, -1.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 8 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n",
      "actions: [6, 2, 7, 2, 3, 3, 8, 3, 0, 4, 3, 6, 2, 2, 1, 0, 3, 6, 6, 2, 0, 2, 3, 7, 5, 2, 1, 1, 0, 8, 3, 4, 0, 2, 4, 1, 6, 4, 7, 2, 2, 3, 3, 1, 4, 2, 4, 1, 2, 4, 2, 5, 3, 0, 1, 8, 7, 3, 5, 8, 5, 8, 7, 3, 3, 2, 6, 3, 0, 3, 0, 8, 6, 2, 2, 5, 3, 0, 0, 0, 5, 3, 7, 7, 6, 0, 3, 8, 8, 5, 7, 8, 1, 5, 6, 4, 0, 7, 6, 7, 8, 8, 8, 2, 4, 7, 8, 1, 7, 2, 2, 5, 5, 2, 0, 2, 7, 1, 4, 1, 0, 6, 5, 8, 1, 2, 6, 2, 8, 8, 3, 2, 3, 5, 6, 1, 4, 4, 5, 3, 3, 1, 7, 3, 2, 1, 7, 3, 0, 5, 6, 4, 0, 3, 7, 2, 2, 6, 2, 0, 7, 0, 7, 3, 3, 5, 2, 3, 5, 4, 7, 3, 2, 5, 4, 2, 6, 2, 6, 4, 2, 0, 4, 2, 4, 8, 8, 2, 4, 3, 4, 2, 0, 5, 0, 8, 7, 2, 0, 6] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 9 finished\n",
      "actions: [2, 2, 4, 8, 8, 0, 2, 0, 2, 8, 3, 0, 6, 0, 2, 2, 2, 2, 4, 1, 7, 6, 7, 2, 4, 1, 0, 4, 2, 5, 5, 4, 2, 1, 5, 2, 2, 5, 4, 2, 3, 4, 6, 0, 1, 3, 2, 3, 6, 0, 3, 8, 2, 2, 0, 6, 2, 5, 2, 5, 8, 0, 2, 8, 2, 1, 5, 1, 0, 3, 4, 0, 3, 2, 4, 6, 5, 4, 2, 6, 3, 6, 0, 3, 6, 8, 7, 3, 7, 6, 4, 6, 5, 0, 6, 5, 6, 8, 4, 7, 3, 0, 3, 1, 5, 0, 5, 8, 1, 2, 2, 4, 3, 1, 7, 6, 5, 7, 3, 0, 4, 7, 4, 2, 3, 0, 1, 4, 2, 1, 7, 0, 4, 0, 4, 6, 1, 7, 4, 7, 6, 1, 2, 1, 3, 2, 4, 6, 2, 7, 1, 3, 4, 2, 1, 1, 3, 0, 6, 2, 2, 2, 3, 2, 2, 0, 2, 0, 4, 1, 1, 1, 2, 4, 3, 6, 1, 6, 0, 7, 1, 7, 8, 5, 2, 8, 0, 1, 1, 3, 2, 5, 2, 2, 2, 2, 2, 7, 6, 8] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 10 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n",
      "-0.08571428571428559 0.0\n",
      "actions: [1, 2, 5, 1, 6, 1, 0, 5, 8, 2, 4, 6, 0, 0, 0, 2, 7, 0, 5, 8, 8, 3, 3, 0, 5, 2, 7, 7, 2, 0, 2, 8, 5, 1, 1, 0, 2, 7, 7, 6, 7, 8, 4, 0, 5, 0, 1, 2, 8, 4, 3, 0, 6, 7, 7, 1, 6, 8, 0, 8, 8, 1, 6, 5, 7, 2, 4, 0, 3, 6, 3, 4, 5, 0, 2, 6, 3, 7, 3, 1, 6, 1, 6, 8, 0, 6, 1, 7, 3, 6, 4, 4, 8, 8, 5, 2, 5, 4, 5, 8, 6, 2, 5, 6, 4, 2, 1, 7, 1, 4, 6, 2, 2, 7, 4, 1, 8, 1, 7, 6, 7, 2, 2, 5, 7, 5, 3, 2, 5, 1, 0, 4, 8, 8, 2, 5, 1, 2, 3, 2, 5, 2, 1, 0, 4, 6, 8, 0, 2, 2, 3, 1, 2, 7, 3, 7, 6, 2, 1, 5, 2, 6, 0, 7, 8, 3, 2, 5, 6, 2, 6, 1, 5, 4, 8, 6, 6, 7, 0, 5, 2, 3, 7, 0, 2, 2, 2, 4, 2, 2, 3, 1, 6, 2, 7, 6, 7, 2, 1, 6] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 11 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [3, 7, 1, 4, 8, 2, 5, 6, 4, 7, 2, 0, 5, 5, 2, 6, 2, 1, 1, 2, 3, 2, 4, 8, 3, 5, 6, 7, 6, 8, 5, 8, 2, 5, 2, 2, 5, 4, 6, 4, 8, 8, 7, 2, 4, 3, 2, 1, 3, 2, 7, 0, 2, 7, 5, 4, 3, 7, 7, 7, 4, 7, 5, 7, 7, 7, 8, 1, 3, 5, 8, 2, 2, 3, 2, 5, 6, 6, 8, 3, 2, 3, 7, 0, 3, 2, 0, 7, 7, 2, 5, 5, 7, 6, 4, 2, 2, 8, 0, 8, 0, 5, 6, 0, 5, 1, 3, 4, 4, 2, 8, 3, 2, 3, 8, 1, 0, 0, 3, 2, 0, 6, 2, 1, 7, 5, 3, 1, 1, 2, 1, 8, 0, 0, 2, 2, 6, 1, 8, 7, 6, 5, 8, 5, 5, 8, 8, 4, 3, 7, 4, 3, 0, 1, 2, 3, 3, 4, 7, 1, 3, 2, 8, 1, 6, 0, 6, 2, 0, 4, 2, 0, 5, 0, 7, 3, 7, 8, 2, 3, 8, 6, 7, 3, 1, 8, 2, 3, 2, 7, 3, 5, 2, 2, 4, 3, 6, 4, 6, 7] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 12 finished\n",
      "actions: [2, 8, 0, 1, 5, 7, 7, 5, 2, 5, 7, 7, 7, 1, 4, 8, 4, 0, 2, 4, 2, 2, 6, 2, 2, 4, 6, 1, 4, 4, 2, 1, 2, 0, 2, 6, 4, 5, 8, 8, 7, 6, 3, 5, 2, 1, 2, 3, 3, 6, 4, 3, 2, 4, 8, 6, 2, 5, 6, 3, 8, 8, 2, 7, 1, 4, 8, 1, 2, 5, 8, 5, 8, 1, 6, 0, 6, 6, 4, 1, 2, 2, 7, 2, 5, 3, 5, 4, 8, 1, 7, 4, 5, 1, 2, 8, 6, 0, 0, 0, 1, 7, 3, 3, 7, 4, 1, 4, 3, 7, 7, 4, 1, 3, 4, 2, 1, 2, 0, 3, 7, 1, 4, 5, 1, 2, 7, 4, 8, 3, 2, 2, 0, 7, 2, 1, 2, 8, 8, 1, 8, 8, 1, 5, 6, 2, 6, 2, 6, 3, 6, 2, 2, 3, 2, 0, 1, 4, 7, 2, 6, 2, 2, 2, 2, 0, 2, 5, 8, 7, 6, 2, 6, 0, 5, 6, 2, 4, 6, 2, 3, 2, 3, 8, 4, 8, 7, 6, 8, 5, 6, 8, 7, 2, 2, 3, 5, 8, 4, 8] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 13 finished\n",
      "actions: [4, 2, 0, 0, 2, 2, 4, 3, 5, 2, 4, 2, 5, 7, 2, 6, 1, 8, 2, 5, 2, 2, 0, 2, 2, 5, 7, 8, 2, 3, 0, 2, 1, 3, 6, 3, 1, 0, 8, 2, 5, 5, 3, 1, 1, 1, 6, 4, 0, 4, 5, 8, 0, 1, 0, 2, 2, 3, 1, 6, 7, 6, 6, 7, 0, 2, 8, 5, 5, 8, 3, 3, 2, 2, 7, 2, 5, 1, 8, 6, 8, 2, 5, 8, 8, 0, 4, 2, 6, 2, 7, 3, 8, 6, 6, 8, 5, 8, 3, 6, 5, 1, 4, 6, 7, 1, 2, 4, 1, 8, 3, 5, 8, 4, 7, 8, 2, 0, 2, 4, 6, 2, 4, 4, 4, 4, 0, 2, 4, 3, 1, 5, 3, 0, 6, 4, 2, 2, 4, 8, 6, 3, 1, 2, 0, 2, 0, 2, 2, 3, 3, 1, 5, 7, 8, 0, 2, 4, 2, 0, 8, 2, 1, 2, 8, 2, 4, 5, 0, 7, 8, 0, 4, 1, 6, 4, 3, 3, 4, 6, 2, 4, 5, 2, 2, 2, 7, 1, 0, 7, 2, 1, 5, 8, 8, 6, 2, 5, 8, 4] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 14 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n",
      "actions: [4, 3, 8, 2, 2, 2, 2, 5, 1, 2, 8, 2, 0, 0, 3, 5, 2, 0, 2, 1, 6, 0, 3, 7, 2, 1, 5, 0, 4, 8, 6, 2, 6, 2, 0, 4, 8, 8, 3, 1, 2, 3, 5, 5, 3, 0, 7, 3, 1, 3, 1, 2, 5, 3, 3, 6, 8, 7, 5, 7, 6, 6, 4, 4, 0, 7, 2, 1, 4, 2, 4, 4, 2, 7, 5, 0, 1, 8, 2, 6, 6, 7, 2, 5, 4, 7, 0, 0, 2, 4, 2, 7, 8, 1, 3, 1, 1, 2, 4, 7, 2, 0, 7, 6, 1, 5, 2, 3, 2, 0, 2, 1, 1, 0, 0, 0, 2, 5, 5, 8, 3, 2, 0, 8, 5, 8, 0, 1, 2, 7, 5, 2, 2, 2, 6, 6, 4, 3, 3, 0, 6, 0, 2, 7, 6, 2, 2, 4, 6, 5, 3, 7, 0, 3, 2, 3, 3, 5, 2, 7, 3, 2, 5, 2, 2, 0, 2, 2, 2, 0, 4, 2, 5, 7, 2, 7, 4, 8, 1, 0, 5, 4, 2, 0, 8, 8, 3, 2, 3, 5, 7, 0, 1, 5, 3, 5, 3, 1, 0, 1] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 15 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [2, 8, 2, 8, 2, 2, 2, 2, 8, 2, 3, 4, 1, 6, 2, 7, 3, 2, 8, 2, 8, 7, 3, 2, 4, 3, 3, 2, 7, 6, 6, 4, 2, 2, 6, 2, 6, 0, 3, 1, 7, 5, 1, 2, 4, 3, 8, 4, 7, 3, 7, 2, 4, 1, 5, 2, 5, 7, 3, 5, 2, 0, 2, 7, 8, 2, 2, 8, 0, 1, 1, 3, 8, 1, 1, 2, 6, 4, 3, 0, 3, 8, 6, 3, 3, 7, 4, 3, 5, 2, 2, 3, 3, 1, 8, 7, 8, 2, 3, 4, 1, 5, 4, 2, 7, 2, 4, 3, 2, 1, 2, 2, 0, 3, 5, 4, 0, 2, 7, 5, 2, 1, 3, 6, 0, 1, 2, 6, 8, 3, 1, 8, 6, 6, 6, 3, 3, 2, 2, 3, 2, 6, 3, 2, 3, 0, 1, 2, 3, 8, 3, 0, 0, 1, 2, 7, 2, 2, 4, 2, 1, 1, 0, 3, 4, 4, 5, 3, 6, 0, 7, 1, 5, 7, 6, 7, 1, 7, 3, 6, 2, 0, 4, 3, 0, 6, 5, 6, 4, 7, 7, 2, 2, 4, 2, 2, 3, 3, 2, 6] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 16 finished\n",
      "actions: [5, 8, 5, 4, 2, 6, 8, 0, 3, 0, 8, 2, 4, 1, 6, 7, 8, 7, 4, 3, 1, 0, 6, 1, 3, 3, 5, 5, 1, 3, 3, 2, 4, 0, 2, 6, 7, 2, 2, 2, 2, 5, 0, 5, 8, 0, 1, 2, 2, 7, 6, 4, 6, 7, 1, 7, 4, 1, 8, 1, 4, 0, 3, 6, 0, 0, 8, 2, 3, 5, 3, 5, 6, 2, 2, 5, 7, 1, 4, 2, 1, 1, 7, 2, 1, 3, 1, 5, 2, 2, 2, 7, 7, 5, 2, 5, 2, 1, 2, 7, 3, 6, 2, 2, 2, 6, 2, 2, 8, 1, 2, 2, 2, 4, 0, 5, 2, 7, 0, 2, 7, 7, 8, 5, 6, 8, 5, 6, 6, 2, 7, 1, 3, 2, 8, 7, 5, 4, 3, 0, 7, 1, 2, 8, 8, 2, 4, 1, 8, 4, 5, 2, 4, 8, 7, 0, 3, 2, 4, 7, 2, 8, 2, 7, 3, 2, 0, 7, 6, 7, 7, 1, 4, 4, 5, 6, 2, 3, 4, 5, 6, 6, 2, 7, 2, 7, 7, 8, 2, 2, 4, 1, 8, 8, 2, 3, 2, 6, 0, 6] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 17 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n",
      "actions: [0, 2, 0, 1, 0, 2, 2, 0, 7, 2, 1, 2, 4, 4, 5, 6, 1, 1, 8, 7, 5, 2, 4, 2, 3, 6, 3, 1, 5, 0, 2, 7, 2, 8, 2, 4, 2, 0, 5, 0, 5, 1, 2, 4, 7, 4, 1, 1, 6, 7, 6, 2, 2, 1, 2, 4, 8, 0, 6, 3, 6, 3, 2, 7, 7, 2, 7, 2, 2, 2, 7, 7, 1, 6, 3, 1, 4, 7, 3, 2, 1, 2, 0, 0, 2, 1, 6, 1, 6, 4, 3, 7, 2, 7, 1, 5, 1, 6, 2, 7, 3, 2, 4, 0, 3, 6, 7, 0, 2, 8, 3, 7, 2, 6, 2, 6, 6, 3, 3, 2, 2, 7, 5, 2, 2, 1, 5, 8, 5, 0, 7, 7, 2, 3, 6, 2, 4, 2, 5, 3, 8, 6, 2, 7, 5, 5, 5, 2, 0, 2, 2, 1, 5, 2, 4, 4, 6, 0, 6, 5, 0, 0, 3, 8, 1, 1, 2, 4, 6, 7, 1, 3, 8, 2, 1, 0, 2, 1, 5, 2, 2, 5, 8, 7, 8, 2, 5, 8, 1, 2, 0, 2, 4, 1, 2, 4, 8, 8, 2, 3] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 18 finished\n",
      "actions: [2, 7, 8, 1, 4, 6, 1, 1, 2, 8, 6, 2, 2, 2, 1, 0, 2, 1, 8, 7, 6, 2, 8, 6, 2, 5, 2, 6, 7, 2, 7, 4, 8, 6, 2, 2, 4, 1, 1, 2, 6, 1, 0, 2, 7, 5, 2, 7, 6, 1, 7, 0, 4, 2, 6, 2, 2, 6, 0, 1, 2, 6, 2, 2, 1, 2, 1, 7, 4, 2, 7, 6, 8, 2, 1, 2, 2, 6, 2, 4, 6, 7, 6, 2, 4, 2, 2, 6, 0, 4, 1, 3, 4, 0, 6, 2, 7, 7, 8, 2, 3, 7, 4, 4, 2, 2, 2, 0, 7, 4, 6, 5, 5, 8, 2, 2, 5, 2, 8, 2, 2, 5, 1, 3, 1, 2, 2, 2, 0, 2, 2, 5, 2, 4, 2, 4, 3, 4, 2, 6, 2, 0, 0, 7, 7, 0, 7, 6, 0, 2, 1, 2, 8, 3, 3, 1, 5, 7, 6, 5, 2, 6, 5, 2, 4, 6, 6, 3, 2, 4, 8, 5, 5, 0, 4, 2, 5, 8, 6, 1, 1, 6, 2, 2, 7, 8, 2, 2, 7, 4, 2, 4, 3, 2, 0, 2, 6, 6, 5, 4] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 19 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [1, 0, 3, 3, 2, 2, 4, 4, 0, 2, 1, 2, 0, 8, 2, 1, 7, 5, 2, 6, 2, 2, 0, 8, 7, 8, 3, 3, 5, 0, 5, 1, 7, 8, 5, 2, 7, 8, 4, 6, 6, 8, 2, 2, 0, 2, 1, 0, 2, 4, 8, 1, 1, 1, 4, 2, 5, 0, 2, 8, 4, 8, 4, 2, 2, 3, 6, 4, 0, 2, 5, 2, 3, 2, 8, 2, 1, 2, 2, 2, 2, 1, 4, 1, 6, 5, 2, 1, 2, 8, 8, 1, 1, 0, 2, 5, 0, 2, 2, 4, 5, 7, 2, 6, 5, 2, 4, 3, 0, 3, 3, 6, 2, 2, 7, 6, 2, 6, 0, 7, 8, 2, 3, 2, 2, 3, 1, 6, 6, 3, 2, 0, 4, 6, 2, 2, 2, 7, 4, 2, 4, 6, 2, 2, 4, 4, 2, 8, 1, 2, 2, 2, 7, 2, 3, 2, 2, 6, 5, 3, 6, 2, 7, 0, 8, 6, 6, 4, 4, 7, 3, 8, 3, 1, 6, 7, 2, 3, 2, 5, 2, 1, 7, 4, 2, 0, 6, 1, 6, 3, 6, 6, 6, 2, 0, 1, 1, 2, 7, 1] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 20 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Not enough free spots (#4) to place 1 player and 3 boxes.\n",
      "[SOKOBAN] Retry . . .\n",
      "-0.09999999999999987 0.0\n",
      "actions: [0, 0, 6, 0, 2, 8, 2, 7, 2, 1, 5, 2, 2, 6, 8, 5, 2, 5, 1, 0, 5, 8, 8, 2, 7, 3, 0, 0, 5, 2, 2, 4, 8, 3, 4, 8, 0, 2, 5, 2, 3, 2, 7, 2, 6, 2, 7, 0, 0, 7, 6, 0, 2, 2, 3, 0, 0, 2, 2, 4, 7, 6, 8, 4, 7, 7, 3, 7, 7, 2, 4, 7, 3, 6, 2, 2, 3, 2, 6, 2, 2, 7, 6, 2, 1, 7, 8, 5, 6, 1, 3, 1, 8, 2, 3, 1, 6, 3, 5, 3, 6, 1, 5, 1, 8, 2, 2, 6, 5, 2, 2, 3, 0, 4, 1, 7, 7, 2, 0, 5, 8, 5, 8, 6, 3, 7, 2, 4, 0, 2, 2, 4, 6, 8, 8, 0, 5, 0, 6, 8, 0, 6, 5, 3, 7, 3, 0, 6, 3, 3, 8, 7, 7, 1, 0, 5, 0, 7, 2, 2, 2, 1, 7, 7, 6, 8, 1, 2, 3, 0, 8, 7, 1, 2, 2, 2, 0, 8, 2, 3, 2, 6, 3, 2, 7, 2, 2, 5, 5, 6, 7, 1, 4, 4, 5, 2, 2, 6, 1, 8] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 21 finished\n",
      "actions: [2, 2, 2, 2, 4, 0, 2, 3, 2, 8, 2, 2, 5, 3, 8, 5, 2, 2, 5, 0, 5, 6, 2, 7, 6, 3, 2, 3, 1, 2, 4, 8, 2, 2, 7, 7, 4, 4, 2, 3, 0, 7, 2, 2, 8, 3, 2, 8, 2, 6, 6, 2, 8, 6, 6, 2, 1, 8, 5, 1, 2, 6, 1, 7, 1, 1, 2, 6, 1, 0, 5, 3, 2, 4, 2, 2, 2, 2, 5, 2, 2, 6, 4, 6, 3, 3, 4, 0, 2, 5, 2, 5, 6, 5, 0, 5, 4, 2, 7, 2, 1, 0, 3, 2, 3, 0, 6, 7, 1, 2, 0, 1, 8, 8, 2, 7, 8, 8, 2, 2, 2, 2, 4, 2, 0, 6, 5, 0, 1, 7, 4, 7, 7, 3, 2, 7, 0, 4, 3, 0, 2, 7, 6, 7, 8, 6, 2, 4, 8, 0, 2, 3, 6, 1, 7, 4, 2, 2, 4, 2, 2, 1, 2, 2, 0, 5, 2, 2, 4, 2, 6, 2, 5, 2, 1, 8, 5, 8, 2, 0, 6, 3, 3, 1, 1, 1, 2, 8, 2, 2, 0, 2, 5, 3, 2, 8, 5, 2, 2, 2] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 22 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n",
      "actions: [4, 0, 7, 7, 1, 1, 6, 4, 4, 1, 2, 5, 4, 8, 3, 1, 4, 0, 1, 6, 7, 2, 2, 2, 8, 2, 8, 5, 2, 6, 3, 8, 1, 4, 6, 6, 7, 2, 3, 7, 5, 7, 1, 2, 5, 2, 2, 2, 2, 2, 4, 1, 2, 5, 7, 4, 4, 7, 2, 0, 3, 8, 0, 2, 0, 8, 8, 4, 2, 1, 3, 2, 7, 4, 1, 2, 8, 4, 2, 3, 8, 3, 1, 5, 2, 2, 4, 2, 2, 8, 2, 2, 6, 3, 3, 2, 4, 5, 1, 6, 5, 2, 5, 8, 5, 4, 6, 8, 2, 6, 4, 6, 8, 8, 0, 2, 2, 2, 7, 5, 0, 1, 1, 4, 4, 1, 7, 4, 8, 0, 3, 3, 2, 7, 7, 2, 0, 7, 2, 8, 5, 2, 2, 6, 2, 8, 4, 2, 2, 1, 3, 8, 0, 2, 7, 2, 7, 6, 8, 0, 5, 1, 7, 7, 0, 2, 5, 8, 0, 3, 6, 2, 2, 2, 1, 8, 6, 5, 6, 3, 4, 8, 2, 6, 8, 7, 3, 7, 5, 8, 8, 6, 8, 2, 8, 1, 4, 1, 1, 2] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 23 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [8, 8, 7, 2, 2, 0, 6, 2, 0, 2, 0, 3, 2, 4, 0, 2, 8, 5, 8, 2, 2, 6, 4, 8, 2, 2, 5, 8, 2, 1, 4, 7, 2, 2, 0, 4, 5, 2, 6, 0, 5, 8, 8, 1, 4, 4, 7, 5, 5, 0, 4, 4, 7, 7, 2, 1, 1, 7, 2, 2, 2, 2, 7, 8, 8, 7, 1, 1, 3, 1, 1, 3, 8, 4, 3, 0, 2, 4, 3, 7, 5, 0, 2, 2, 1, 7, 6, 6, 2, 2, 2, 0, 0, 6, 1, 1, 3, 2, 3, 8, 0, 4, 3, 7, 5, 2, 7, 3, 8, 2, 7, 2, 0, 1, 8, 8, 1, 4, 4, 5, 5, 0, 2, 0, 0, 4, 8, 6, 2, 0, 1, 2, 1, 3, 5, 3, 3, 1, 3, 2, 0, 5, 3, 8, 2, 0, 7, 2, 2, 6, 6, 2, 5, 4, 2, 2, 4, 4, 3, 7, 1, 8, 2, 2, 1, 1, 6, 1, 1, 5, 3, 2, 2, 2, 1, 2, 1, 2, 0, 2, 7, 7, 2, 6, 2, 5, 8, 5, 2, 6, 2, 2, 2, 2, 8, 5, 8, 4, 7, 1] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 24 finished\n",
      "actions: [6, 2, 2, 8, 1, 2, 4, 3, 5, 4, 6, 4, 2, 2, 7, 3, 7, 0, 6, 0, 3, 4, 2, 2, 6, 8, 3, 4, 6, 1, 2, 1, 6, 7, 3, 8, 6, 2, 0, 2, 2, 2, 2, 1, 2, 5, 3, 2, 8, 2, 3, 6, 5, 2, 5, 5, 2, 5, 2, 2, 4, 2, 3, 0, 2, 2, 0, 4, 3, 3, 4, 6, 1, 2, 2, 7, 2, 2, 8, 3, 2, 5, 7, 5, 2, 2, 2, 3, 8, 2, 2, 5, 2, 1, 7, 4, 7, 1, 2, 1, 5, 3, 5, 6, 3, 6, 2, 2, 7, 7, 5, 0, 2, 0, 4, 2, 2, 5, 2, 8, 2, 3, 2, 2, 6, 0, 7, 2, 4, 4, 7, 3, 4, 3, 2, 6, 5, 2, 3, 8, 5, 2, 7, 8, 1, 0, 6, 2, 6, 5, 0, 2, 7, 2, 8, 8, 5, 7, 1, 6, 5, 7, 3, 6, 2, 2, 8, 2, 2, 2, 7, 4, 5, 1, 6, 2, 2, 1, 5, 4, 8, 2, 1, 2, 7, 6, 2, 4, 1, 4, 1, 0, 3, 2, 3, 8, 7, 7, 1, 2] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 25 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n",
      "actions: [5, 0, 0, 4, 2, 3, 1, 1, 0, 4, 2, 6, 2, 4, 3, 2, 1, 5, 7, 1, 1, 8, 3, 2, 8, 5, 2, 8, 7, 2, 4, 2, 2, 5, 1, 6, 1, 7, 2, 2, 2, 1, 2, 8, 5, 2, 2, 4, 1, 1, 8, 2, 6, 3, 2, 8, 3, 0, 2, 8, 2, 3, 7, 4, 2, 4, 2, 2, 4, 2, 3, 4, 2, 0, 7, 7, 2, 2, 4, 5, 7, 2, 2, 2, 1, 2, 2, 7, 1, 8, 8, 7, 0, 8, 3, 2, 3, 1, 3, 2, 1, 7, 3, 0, 2, 7, 7, 5, 2, 7, 1, 2, 1, 7, 2, 7, 3, 2, 2, 1, 1, 2, 1, 6, 7, 2, 8, 2, 8, 2, 2, 7, 2, 0, 2, 2, 6, 0, 2, 8, 4, 2, 3, 1, 1, 3, 2, 4, 7, 7, 7, 8, 2, 2, 1, 8, 1, 5, 2, 1, 0, 2, 1, 2, 2, 2, 3, 4, 8, 8, 1, 6, 0, 2, 2, 7, 8, 1, 0, 2, 1, 2, 2, 0, 1, 2, 1, 2, 2, 4, 4, 5, 4, 3, 2, 4, 8, 7, 1, 2] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 26 finished\n",
      "actions: [2, 4, 5, 3, 3, 8, 2, 2, 2, 7, 6, 2, 2, 0, 0, 2, 4, 2, 2, 2, 8, 6, 7, 6, 1, 0, 3, 0, 2, 4, 4, 5, 4, 2, 3, 5, 6, 8, 6, 2, 0, 3, 8, 3, 8, 2, 8, 0, 0, 2, 2, 2, 4, 1, 0, 4, 2, 8, 2, 2, 0, 1, 4, 3, 0, 6, 2, 6, 6, 2, 4, 7, 5, 4, 0, 1, 4, 2, 8, 2, 0, 2, 2, 7, 2, 2, 1, 1, 4, 1, 1, 2, 2, 1, 3, 2, 8, 6, 5, 2, 6, 2, 3, 7, 5, 8, 3, 8, 7, 5, 2, 2, 0, 2, 3, 3, 2, 2, 2, 4, 7, 8, 5, 8, 3, 6, 1, 5, 0, 5, 0, 7, 7, 4, 2, 8, 4, 2, 6, 3, 7, 7, 2, 1, 0, 5, 5, 7, 2, 2, 7, 1, 2, 1, 8, 5, 2, 7, 8, 2, 2, 6, 2, 6, 3, 2, 2, 7, 3, 5, 0, 2, 2, 3, 2, 2, 2, 0, 2, 8, 2, 1, 3, 1, 8, 6, 2, 4, 6, 3, 7, 8, 6, 1, 2, 8, 4, 7, 2, 2] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 27 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [1, 3, 2, 2, 8, 0, 8, 2, 2, 3, 2, 3, 2, 2, 5, 4, 2, 1, 2, 3, 2, 5, 4, 4, 2, 2, 2, 8, 4, 1, 7, 0, 7, 7, 2, 5, 2, 3, 2, 8, 6, 8, 2, 2, 2, 1, 5, 0, 5, 8, 0, 2, 7, 3, 3, 6, 2, 2, 2, 2, 7, 4, 8, 2, 2, 0, 2, 6, 6, 3, 8, 5, 6, 4, 3, 0, 1, 2, 2, 2, 3, 8, 3, 2, 2, 2, 8, 8, 2, 2, 7, 1, 2, 8, 2, 0, 2, 2, 4, 5, 2, 4, 3, 8, 8, 1, 2, 4, 2, 2, 2, 4, 7, 2, 8, 2, 2, 6, 7, 7, 7, 3, 7, 4, 7, 2, 8, 0, 8, 4, 6, 5, 3, 7, 2, 6, 2, 2, 0, 1, 2, 7, 0, 2, 2, 1, 1, 3, 2, 7, 3, 8, 2, 4, 2, 0, 3, 0, 2, 1, 2, 7, 8, 5, 7, 6, 8, 2, 2, 2, 4, 2, 2, 1, 2, 6, 2, 6, 2, 0, 6, 2, 5, 8, 6, 5, 2, 5, 5, 5, 4, 2, 7, 6, 3, 3, 2, 0, 3, 2] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 28 finished\n",
      "actions: [3, 6, 2, 2, 0, 2, 2, 2, 2, 8, 2, 8, 3, 4, 6, 8, 1, 2, 2, 2, 4, 7, 8, 2, 6, 8, 7, 2, 0, 2, 8, 1, 2, 2, 2, 8, 2, 7, 2, 1, 1, 8, 2, 2, 8, 3, 2, 2, 2, 0, 4, 2, 5, 6, 6, 1, 1, 4, 2, 8, 0, 3, 2, 2, 6, 4, 4, 0, 6, 1, 1, 2, 5, 2, 2, 1, 7, 5, 6, 2, 7, 0, 1, 2, 6, 2, 8, 5, 5, 7, 6, 4, 6, 0, 7, 7, 2, 2, 1, 0, 2, 4, 7, 4, 2, 1, 7, 4, 2, 2, 2, 2, 2, 2, 1, 8, 2, 3, 7, 2, 3, 2, 2, 4, 5, 2, 2, 7, 7, 4, 5, 3, 6, 5, 0, 2, 4, 2, 7, 0, 1, 7, 2, 2, 5, 1, 7, 1, 0, 8, 2, 0, 0, 1, 3, 2, 0, 2, 1, 1, 5, 2, 5, 2, 0, 2, 5, 7, 2, 2, 2, 6, 2, 7, 6, 2, 3, 2, 0, 0, 8, 6, 2, 3, 6, 5, 2, 7, 2, 4, 5, 2, 6, 2, 5, 2, 4, 2, 2, 3] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 29 finished\n",
      "actions: [2, 2, 8, 6, 6, 2, 2, 2, 0, 0, 4, 2, 8, 4, 2, 0, 2, 4, 7, 1, 2, 5, 1, 5, 2, 5, 0, 4, 1, 1, 3, 0, 3, 1, 0, 5, 0, 1, 2, 2, 2, 7, 5, 7, 2, 6, 0, 4, 3, 3, 2, 2, 6, 2, 8, 8, 2, 6, 7, 5, 2, 6, 3, 0, 0, 2, 7, 6, 2, 5, 1, 6, 2, 4, 2, 2, 2, 0, 3, 1, 2, 2, 7, 5, 2, 2, 6, 1, 2, 3, 7, 6, 3, 2, 7, 6, 3, 5, 8, 1, 2, 2, 2, 6, 5, 1, 2, 7, 2, 5, 7, 2, 4, 7, 0, 6, 6, 5, 2, 5, 3, 3, 1, 7, 2, 4, 2, 2, 2, 3, 4, 8, 2, 0, 2, 5, 5, 2, 7, 2, 1, 2, 5, 2, 6, 4, 4, 6, 0, 0, 0, 0, 2, 3, 8, 2, 7, 7, 1, 5, 2, 3, 5, 7, 2, 2, 2, 0, 8, 6, 6, 5, 6, 0, 3, 2, 4, 4, 0, 2, 3, 5, 4, 2, 7, 1, 1, 0, 8, 7, 2, 1, 7, 8, 6, 0, 2, 2, 4, 7] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 30 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n",
      "-0.04285714285714283 0.0\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n",
      "actions: [2, 1, 4, 0, 1, 6, 2, 2, 4, 3, 2, 1, 4, 2, 8, 4, 7, 2, 2, 3, 7, 0, 2, 6, 4, 6, 2, 8, 4, 2, 0, 1, 0, 8, 1, 5, 3, 7, 1, 2, 2, 1, 3, 7, 2, 2, 2, 1, 0, 8, 0, 2, 4, 5, 3, 3, 4, 0, 2, 5, 6, 1, 0, 0, 2, 5, 7, 2, 2, 1, 2, 7, 2, 2, 8, 3, 7, 5, 1, 2, 5, 2, 2, 2, 2, 8, 4, 2, 2, 2, 8, 4, 2, 8, 6, 0, 0, 4, 2, 3, 7, 8, 1, 8, 4, 0, 2, 6, 2, 2, 2, 2, 1, 2, 2, 2, 3, 2, 2, 2, 0, 1, 0, 6, 1, 3, 3, 5, 6, 8, 0, 8, 2, 5, 0, 0, 5, 3, 0, 6, 2, 2, 6, 3, 2, 4, 3, 5, 2, 3, 3, 2, 3, 6, 4, 4, 3, 0, 4, 5, 2, 2, 2, 1, 7, 2, 1, 7, 4, 4, 2, 1, 2, 5, 2, 5, 2, 0, 5, 2, 6, 0, 3, 4, 6, 2, 7, 5, 2, 2, 8, 2, 2, 2, 1, 2, 2, 2, 2, 2] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 31 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [5, 0, 2, 7, 8, 7, 2, 4, 2, 2, 0, 0, 4, 4, 1, 0, 2, 4, 2, 8, 1, 5, 2, 2, 2, 4, 2, 0, 5, 4, 2, 8, 2, 3, 5, 3, 2, 2, 3, 1, 6, 8, 2, 5, 1, 2, 5, 2, 2, 2, 2, 7, 4, 5, 1, 2, 0, 7, 7, 7, 1, 2, 2, 2, 2, 2, 1, 3, 5, 7, 6, 2, 1, 2, 2, 4, 2, 8, 2, 0, 3, 1, 1, 5, 2, 8, 2, 1, 7, 4, 2, 7, 2, 6, 1, 2, 1, 0, 2, 0, 2, 2, 2, 2, 7, 5, 7, 7, 4, 2, 5, 5, 1, 7, 2, 7, 7, 4, 6, 2, 4, 4, 4, 2, 2, 6, 3, 4, 4, 2, 3, 2, 4, 6, 8, 4, 4, 4, 3, 7, 1, 2, 7, 2, 7, 4, 2, 8, 2, 1, 4, 6, 7, 4, 2, 0, 2, 3, 0, 2, 2, 8, 6, 3, 2, 2, 2, 6, 2, 1, 2, 2, 2, 3, 2, 5, 7, 2, 7, 8, 7, 7, 2, 4, 1, 1, 2, 2, 7, 6, 8, 2, 2, 2, 4, 3, 0, 7, 7, 4] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 32 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n",
      "actions: [1, 5, 0, 2, 5, 7, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 2, 1, 7, 4, 1, 2, 2, 6, 6, 2, 7, 2, 6, 2, 3, 7, 2, 6, 4, 3, 5, 2, 5, 2, 2, 4, 5, 6, 6, 1, 2, 2, 7, 1, 1, 2, 6, 2, 0, 2, 4, 6, 6, 1, 2, 2, 2, 0, 5, 4, 3, 8, 1, 0, 7, 0, 7, 1, 8, 2, 8, 2, 0, 6, 3, 4, 2, 2, 2, 2, 8, 8, 7, 7, 8, 0, 3, 6, 0, 2, 5, 1, 1, 7, 2, 3, 0, 7, 6, 0, 2, 2, 8, 0, 7, 0, 2, 5, 3, 2, 2, 7, 4, 2, 2, 4, 2, 0, 3, 2, 2, 4, 6, 7, 3, 2, 3, 4, 4, 2, 7, 1, 5, 0, 2, 1, 2, 2, 1, 6, 5, 8, 0, 5, 7, 0, 2, 5, 8, 2, 2, 8, 2, 7, 3, 2, 0, 7, 2, 7, 3, 5, 1, 5, 4, 3, 2, 2, 5, 4, 2, 2, 2, 3, 4, 2, 3, 2, 1, 7, 7, 0, 4, 3, 4, 7, 2, 6, 2, 2, 3, 1, 2] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 33 finished\n",
      "actions: [5, 2, 3, 2, 2, 2, 7, 5, 6, 2, 6, 3, 4, 5, 2, 2, 1, 2, 7, 4, 5, 1, 4, 2, 1, 2, 1, 2, 2, 7, 6, 2, 6, 1, 2, 2, 3, 7, 2, 8, 8, 8, 2, 7, 7, 1, 2, 6, 3, 2, 6, 6, 1, 4, 3, 4, 3, 2, 4, 2, 2, 8, 7, 5, 2, 2, 2, 0, 2, 5, 8, 1, 2, 0, 6, 2, 2, 2, 7, 2, 6, 4, 1, 8, 1, 5, 2, 2, 8, 5, 8, 2, 0, 8, 2, 5, 3, 6, 1, 8, 2, 5, 8, 2, 0, 2, 2, 1, 1, 2, 0, 2, 8, 2, 2, 6, 8, 5, 6, 6, 4, 0, 1, 6, 2, 2, 7, 0, 6, 5, 8, 3, 7, 4, 1, 2, 8, 7, 5, 5, 8, 2, 2, 1, 4, 3, 1, 3, 8, 3, 3, 2, 2, 8, 5, 2, 8, 0, 2, 2, 3, 5, 6, 2, 2, 2, 2, 2, 8, 2, 3, 2, 3, 4, 3, 1, 5, 1, 7, 8, 1, 4, 3, 3, 2, 3, 8, 8, 2, 4, 2, 4, 2, 2, 6, 0, 2, 8, 1, 2] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 34 finished\n",
      "actions: [8, 2, 5, 2, 5, 1, 3, 1, 7, 1, 1, 2, 8, 8, 0, 6, 4, 2, 5, 2, 2, 3, 2, 1, 7, 6, 2, 8, 2, 3, 5, 1, 3, 2, 2, 0, 6, 8, 2, 3, 4, 2, 2, 2, 2, 6, 2, 6, 8, 6, 0, 3, 1, 2, 2, 0, 2, 8, 2, 5, 7, 2, 8, 3, 2, 2, 2, 5, 8, 6, 6, 2, 2, 4, 7, 8, 0, 2, 0, 2, 8, 4, 7, 2, 3, 7, 2, 4, 5, 1, 1, 8, 2, 2, 5, 0, 7, 3, 3, 3, 2, 2, 5, 3, 7, 0, 5, 2, 3, 7, 5, 2, 5, 5, 3, 2, 2, 7, 4, 3, 2, 8, 5, 1, 1, 4, 5, 0, 4, 1, 6, 2, 1, 1, 1, 6, 2, 1, 8, 8, 8, 5, 8, 2, 8, 2, 3, 6, 2, 1, 2, 2, 6, 3, 2, 2, 5, 3, 2, 4, 2, 5, 2, 1, 2, 2, 2, 2, 2, 6, 8, 2, 2, 2, 4, 5, 2, 3, 6, 3, 2, 0, 3, 6, 6, 2, 8, 0, 1, 2, 4, 1, 8, 6, 2, 5, 4, 1, 2, 3] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 35 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [7, 3, 0, 3, 2, 2, 3, 8, 2, 4, 1, 7, 2, 2, 2, 2, 7, 8, 2, 2, 3, 7, 2, 1, 5, 2, 0, 6, 0, 8, 3, 4, 0, 1, 2, 8, 8, 2, 6, 3, 2, 8, 2, 6, 5, 2, 2, 2, 1, 8, 5, 6, 4, 8, 2, 7, 0, 2, 2, 2, 3, 2, 1, 2, 2, 1, 2, 3, 3, 1, 2, 0, 8, 6, 6, 2, 8, 2, 0, 1, 7, 3, 2, 2, 2, 2, 2, 7, 0, 7, 1, 0, 6, 3, 7, 2, 7, 3, 7, 7, 4, 2, 6, 5, 2, 5, 8, 7, 7, 3, 3, 1, 2, 2, 1, 0, 6, 2, 2, 0, 6, 2, 8, 5, 6, 7, 2, 2, 7, 1, 3, 2, 7, 7, 2, 1, 3, 2, 5, 2, 6, 2, 1, 1, 3, 6, 2, 7, 1, 2, 7, 2, 0, 0, 2, 2, 2, 2, 1, 2, 0, 2, 2, 4, 6, 4, 0, 1, 2, 5, 3, 2, 2, 2, 2, 2, 5, 3, 2, 5, 4, 3, 2, 2, 2, 2, 8, 0, 2, 5, 1, 5, 7, 7, 8, 2, 3, 4, 2, 1] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 36 finished\n",
      "actions: [2, 2, 3, 7, 2, 3, 8, 8, 7, 8, 2, 2, 4, 3, 3, 7, 2, 6, 6, 0, 6, 1, 5, 7, 7, 4, 2, 4, 7, 7, 6, 6, 5, 2, 2, 0, 2, 2, 3, 2, 2, 3, 7, 4, 4, 8, 2, 2, 2, 2, 0, 2, 2, 0, 8, 2, 0, 4, 2, 2, 2, 2, 0, 4, 2, 8, 2, 3, 2, 3, 2, 2, 7, 0, 2, 2, 6, 6, 5, 2, 2, 1, 4, 7, 2, 2, 2, 2, 0, 5, 0, 6, 2, 2, 2, 4, 4, 1, 2, 1, 4, 2, 2, 2, 6, 6, 3, 4, 7, 8, 3, 2, 5, 5, 3, 4, 2, 1, 2, 2, 2, 2, 2, 5, 7, 3, 2, 2, 2, 2, 6, 2, 2, 3, 5, 5, 8, 7, 2, 2, 2, 2, 8, 8, 3, 2, 2, 8, 5, 8, 5, 2, 0, 4, 0, 5, 7, 7, 1, 4, 6, 2, 2, 6, 1, 1, 6, 2, 5, 2, 2, 6, 2, 1, 5, 3, 2, 6, 2, 4, 8, 2, 2, 2, 6, 6, 2, 7, 4, 1, 0, 5, 7, 2, 5, 1, 0, 6, 2, 6] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 37 finished\n",
      "actions: [2, 2, 6, 4, 2, 8, 5, 1, 7, 2, 0, 2, 1, 6, 6, 2, 2, 2, 2, 2, 0, 4, 4, 2, 5, 2, 2, 0, 1, 2, 0, 2, 2, 3, 2, 2, 6, 3, 2, 2, 3, 2, 6, 0, 6, 8, 8, 3, 4, 2, 5, 1, 0, 2, 2, 8, 2, 2, 0, 3, 4, 4, 4, 2, 4, 0, 2, 0, 2, 5, 0, 1, 2, 1, 0, 2, 3, 2, 2, 2, 8, 5, 7, 7, 2, 7, 4, 8, 5, 1, 2, 1, 3, 0, 2, 2, 8, 8, 2, 1, 6, 1, 2, 2, 2, 2, 2, 2, 2, 7, 4, 6, 7, 5, 7, 4, 3, 2, 1, 2, 8, 2, 7, 8, 1, 3, 3, 3, 2, 7, 3, 4, 2, 5, 0, 4, 8, 0, 2, 2, 1, 0, 7, 2, 0, 0, 2, 3, 2, 2, 2, 8, 8, 7, 2, 2, 5, 6, 1, 6, 2, 0, 7, 5, 8, 2, 3, 4, 6, 2, 6, 6, 0, 2, 8, 2, 1, 2, 2, 2, 8, 2, 0, 4, 2, 2, 7, 2, 6, 7, 5, 2, 0, 5, 1, 2, 1, 2, 2, 6] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 38 finished\n",
      "actions: [3, 4, 1, 2, 4, 4, 8, 2, 2, 8, 2, 7, 3, 2, 5, 4, 2, 2, 0, 2, 3, 2, 7, 4, 2, 2, 0, 2, 5, 7, 2, 0, 3, 7, 2, 2, 2, 2, 2, 5, 8, 0, 2, 4, 3, 2, 6, 4, 3, 5, 2, 0, 2, 8, 2, 4, 2, 6, 2, 5, 2, 2, 5, 5, 0, 2, 7, 2, 2, 6, 2, 5, 4, 0, 6, 2, 2, 6, 2, 2, 5, 7, 8, 1, 5, 1, 3, 7, 2, 6, 6, 2, 0, 3, 3, 5, 2, 8, 6, 2, 2, 2, 8, 2, 2, 6, 2, 2, 2, 7, 2, 1, 2, 0, 7, 6, 2, 3, 2, 7, 2, 2, 7, 2, 7, 6, 2, 2, 6, 2, 2, 2, 2, 2, 4, 1, 2, 2, 5, 2, 8, 2, 2, 2, 1, 0, 0, 0, 0, 5, 7, 7, 2, 6, 8, 8, 7, 2, 4, 2, 2, 3, 7, 8, 3, 2, 1, 0, 7, 3, 5, 2, 2, 1, 2, 2, 2, 4, 2, 7, 2, 5, 7, 2, 2, 3, 2, 2, 0, 2, 2, 2, 0, 5, 8, 2, 7, 1, 2, 2] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 39 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [2, 6, 2, 2, 2, 4, 4, 3, 0, 0, 2, 3, 8, 4, 8, 7, 8, 6, 6, 2, 2, 2, 7, 5, 2, 6, 2, 2, 4, 6, 8, 0, 8, 2, 6, 7, 2, 8, 6, 6, 4, 0, 2, 6, 2, 1, 1, 1, 2, 6, 1, 2, 2, 3, 2, 5, 6, 2, 2, 3, 4, 2, 1, 8, 2, 2, 7, 6, 2, 2, 8, 2, 7, 7, 0, 4, 1, 2, 1, 5, 2, 7, 2, 3, 5, 8, 2, 2, 2, 1, 2, 5, 6, 2, 3, 8, 2, 2, 2, 2, 2, 1, 3, 6, 2, 4, 7, 7, 2, 7, 2, 2, 2, 2, 0, 4, 2, 4, 1, 7, 7, 2, 2, 4, 5, 8, 2, 2, 2, 7, 2, 5, 3, 8, 2, 6, 2, 3, 5, 1, 2, 2, 1, 8, 2, 1, 2, 6, 1, 1, 5, 7, 5, 2, 2, 2, 2, 1, 7, 5, 0, 8, 1, 5, 2, 2, 6, 2, 2, 2, 0, 2, 2, 0, 2, 8, 1, 6, 8, 1, 0, 5, 2, 6, 4, 2, 2, 2, 1, 6, 8, 5, 5, 2, 4, 0, 2, 8, 7, 5] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 40 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n",
      "-0.0714285714285713 0.0\n",
      "actions: [7, 3, 2, 7, 0, 2, 5, 2, 0, 2, 2, 2, 8, 4, 8, 7, 6, 5, 0, 2, 0, 2, 6, 2, 2, 6, 4, 1, 6, 2, 7, 6, 2, 2, 5, 3, 7, 3, 2, 4, 5, 3, 8, 1, 6, 1, 0, 2, 2, 4, 8, 8, 2, 3, 2, 0, 7, 6, 2, 2, 2, 8, 7, 2, 3, 3, 2, 7, 2, 7, 7, 2, 6, 6, 1, 2, 0, 1, 2, 0, 8, 2, 3, 7, 2, 6, 2, 2, 2, 1, 7, 2, 0, 1, 4, 0, 2, 2, 2, 8, 2, 7, 1, 6, 2, 2, 2, 2, 2, 5, 5, 2, 2, 2, 7, 4, 2, 6, 6, 5, 2, 7, 0, 8, 2, 5, 2, 1, 2, 7, 2, 2, 8, 1, 0, 2, 1, 4, 6, 8, 6, 6, 2, 2, 4, 2, 2, 0, 4, 2, 5, 7, 2, 5, 0, 5, 2, 4, 2, 8, 2, 5, 7, 8, 6, 1, 0, 4, 5, 2, 4, 8, 5, 1, 3, 7, 6, 6, 2, 6, 2, 2, 6, 2, 3, 8, 8, 7, 5, 6, 0, 2, 0, 3, 2, 2, 2, 2, 3, 2] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 41 finished\n",
      "actions: [6, 1, 4, 2, 4, 2, 1, 4, 8, 2, 4, 7, 7, 7, 5, 5, 0, 5, 2, 2, 7, 2, 0, 7, 2, 2, 2, 2, 2, 7, 2, 2, 0, 6, 8, 4, 4, 5, 2, 0, 2, 3, 2, 3, 2, 6, 5, 3, 2, 2, 4, 2, 2, 2, 2, 4, 2, 7, 2, 2, 2, 8, 7, 2, 2, 8, 6, 8, 7, 7, 2, 2, 2, 4, 2, 2, 6, 4, 7, 5, 7, 2, 3, 2, 5, 5, 2, 8, 2, 2, 0, 6, 2, 6, 2, 1, 2, 0, 6, 6, 2, 2, 2, 2, 2, 1, 6, 2, 2, 0, 3, 2, 8, 6, 0, 3, 2, 7, 2, 1, 4, 6, 2, 3, 2, 4, 5, 8, 2, 4, 7, 2, 1, 8, 7, 2, 7, 2, 1, 2, 3, 2, 7, 6, 2, 5, 2, 2, 2, 2, 2, 7, 2, 2, 5, 2, 5, 2, 7, 2, 6, 5, 7, 7, 5, 2, 6, 2, 2, 3, 7, 2, 2, 2, 3, 8, 2, 7, 0, 5, 6, 2, 8, 8, 2, 2, 2, 2, 7, 1, 6, 1, 1, 5, 1, 3, 1, 8, 2, 2] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 42 finished\n",
      "actions: [1, 2, 2, 2, 5, 3, 1, 3, 8, 3, 3, 3, 5, 8, 5, 2, 2, 2, 2, 2, 2, 2, 2, 6, 8, 4, 8, 2, 4, 2, 1, 2, 2, 6, 3, 2, 2, 0, 7, 6, 8, 2, 2, 2, 4, 4, 4, 2, 7, 8, 2, 0, 7, 2, 2, 2, 8, 1, 4, 4, 7, 3, 3, 4, 8, 0, 6, 1, 2, 2, 7, 2, 0, 2, 0, 2, 5, 0, 0, 2, 4, 6, 2, 2, 4, 2, 6, 2, 2, 3, 6, 5, 2, 2, 2, 2, 2, 8, 4, 7, 2, 2, 2, 2, 2, 2, 4, 2, 7, 0, 6, 0, 2, 1, 2, 6, 5, 0, 0, 0, 8, 2, 6, 2, 4, 1, 2, 2, 5, 2, 2, 2, 2, 2, 8, 2, 8, 0, 8, 2, 2, 3, 5, 4, 3, 6, 5, 2, 2, 2, 2, 2, 5, 1, 2, 4, 8, 6, 5, 7, 3, 3, 5, 2, 1, 5, 5, 1, 0, 4, 2, 8, 5, 2, 7, 4, 8, 5, 6, 2, 0, 7, 6, 3, 1, 2, 2, 6, 2, 1, 2, 5, 2, 2, 2, 5, 2, 2, 2, 8] rewards: [0.9, -1.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 43 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [6, 7, 2, 6, 7, 2, 4, 2, 4, 0, 0, 0, 8, 8, 0, 2, 2, 1, 0, 2, 7, 2, 6, 4, 7, 4, 7, 2, 0, 0, 3, 2, 2, 2, 1, 5, 7, 2, 2, 2, 6, 2, 3, 2, 2, 2, 8, 1, 8, 2, 2, 5, 3, 2, 2, 1, 2, 3, 3, 3, 2, 2, 6, 2, 5, 6, 8, 8, 2, 2, 2, 2, 8, 4, 1, 6, 4, 2, 2, 2, 6, 2, 7, 2, 8, 2, 2, 1, 2, 2, 5, 6, 8, 2, 2, 2, 4, 0, 2, 3, 2, 8, 7, 7, 2, 0, 2, 3, 8, 1, 8, 2, 0, 2, 1, 6, 4, 3, 6, 0, 6, 2, 4, 6, 5, 8, 2, 7, 2, 7, 2, 2, 4, 7, 1, 2, 3, 1, 5, 8, 2, 2, 2, 2, 6, 1, 2, 2, 2, 6, 2, 2, 8, 2, 2, 2, 2, 2, 0, 0, 2, 7, 7, 3, 1, 3, 8, 0, 0, 2, 8, 2, 2, 7, 7, 8, 2, 3, 5, 0, 2, 2, 8, 2, 2, 7, 3, 2, 6, 2, 5, 0, 2, 2, 2, 2, 1, 2, 7, 2] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 44 finished\n",
      "actions: [3, 6, 2, 3, 0, 2, 7, 3, 2, 7, 2, 7, 3, 1, 2, 7, 2, 8, 3, 5, 5, 4, 2, 3, 0, 7, 3, 4, 1, 8, 2, 2, 8, 2, 6, 7, 4, 2, 3, 2, 5, 1, 2, 5, 1, 0, 1, 6, 8, 2, 2, 5, 2, 2, 2, 8, 0, 2, 8, 5, 4, 5, 1, 7, 2, 2, 5, 2, 1, 3, 4, 5, 2, 2, 2, 2, 2, 1, 2, 0, 2, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 0, 7, 3, 2, 2, 2, 2, 2, 2, 2, 2, 8, 7, 4, 2, 2, 2, 2, 5, 2, 4, 2, 2, 4, 2, 7, 2, 2, 2, 2, 2, 7, 1, 2, 2, 2, 2, 0, 5, 2, 2, 3, 2, 8, 7, 2, 2, 7, 2, 3, 2, 0, 2, 2, 2, 2, 2, 7, 2, 4, 2, 2, 5, 3, 5, 0, 3, 1, 2, 2, 5, 2, 1, 2, 7, 3, 2, 2, 0, 0, 6, 3, 6, 2, 8, 0, 2, 2, 5, 2, 2, 2, 2, 7, 2, 2, 5, 5, 2, 7, 5, 0, 2, 2, 3, 8, 0] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 45 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n",
      "actions: [2, 7, 2, 2, 7, 8, 6, 2, 1, 6, 2, 2, 2, 6, 2, 2, 8, 7, 6, 3, 4, 1, 5, 6, 4, 1, 0, 7, 8, 8, 0, 2, 7, 2, 6, 7, 8, 5, 3, 2, 8, 2, 0, 1, 2, 6, 2, 2, 0, 3, 2, 3, 4, 7, 2, 2, 7, 6, 6, 2, 2, 6, 2, 2, 2, 7, 5, 8, 5, 6, 2, 4, 2, 2, 1, 2, 5, 8, 2, 5, 2, 1, 7, 4, 6, 4, 5, 2, 8, 7, 2, 2, 1, 2, 2, 2, 7, 6, 3, 2, 1, 6, 5, 2, 1, 2, 3, 1, 0, 2, 2, 2, 2, 8, 1, 2, 5, 8, 2, 1, 2, 1, 2, 2, 3, 2, 4, 2, 3, 3, 2, 0, 7, 2, 6, 2, 6, 2, 7, 4, 2, 0, 2, 4, 8, 7, 4, 2, 0, 2, 4, 2, 8, 2, 4, 4, 2, 2, 8, 8, 2, 5, 4, 8, 2, 2, 2, 2, 1, 2, 2, 2, 7, 2, 2, 7, 2, 0, 7, 8, 2, 1, 3, 2, 5, 2, 8, 3, 1, 4, 2, 6, 6, 2, 2, 2, 2, 8, 1, 1] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 46 finished\n",
      "actions: [8, 2, 3, 5, 1, 1, 4, 2, 2, 3, 1, 2, 1, 2, 3, 4, 4, 4, 2, 0, 2, 7, 6, 6, 2, 5, 1, 8, 2, 8, 3, 5, 0, 2, 8, 4, 2, 2, 0, 0, 2, 2, 2, 4, 1, 1, 3, 6, 2, 4, 2, 7, 5, 2, 2, 4, 2, 8, 2, 7, 7, 4, 2, 4, 1, 4, 3, 6, 1, 2, 7, 1, 1, 0, 4, 2, 2, 0, 7, 1, 8, 8, 7, 4, 2, 6, 4, 3, 6, 3, 2, 1, 7, 4, 3, 5, 2, 2, 2, 5, 2, 1, 0, 6, 2, 2, 6, 2, 3, 2, 3, 2, 5, 2, 2, 2, 2, 2, 2, 4, 2, 5, 5, 0, 0, 6, 7, 0, 8, 2, 4, 2, 8, 0, 3, 8, 2, 7, 2, 6, 2, 2, 3, 2, 0, 2, 2, 1, 2, 2, 2, 8, 8, 3, 2, 2, 7, 7, 3, 1, 5, 3, 2, 2, 7, 2, 2, 2, 0, 2, 2, 8, 2, 0, 5, 7, 1, 2, 2, 0, 4, 5, 2, 2, 7, 2, 2, 2, 3, 3, 8, 2, 2, 2, 2, 8, 2, 1, 6, 6] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 47 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [7, 5, 5, 2, 6, 3, 5, 6, 6, 2, 4, 0, 7, 1, 2, 0, 2, 0, 2, 0, 2, 2, 4, 8, 2, 1, 1, 6, 0, 4, 2, 2, 2, 0, 7, 2, 2, 2, 8, 2, 3, 7, 1, 7, 2, 2, 5, 2, 6, 2, 6, 3, 2, 0, 7, 6, 2, 2, 2, 0, 5, 2, 4, 2, 2, 2, 2, 2, 2, 2, 5, 2, 3, 2, 2, 0, 8, 5, 1, 8, 2, 6, 0, 2, 1, 2, 6, 2, 2, 7, 7, 8, 2, 2, 2, 2, 2, 2, 2, 0, 6, 4, 8, 2, 5, 2, 2, 2, 0, 2, 2, 7, 2, 1, 2, 5, 2, 4, 2, 2, 3, 6, 8, 2, 1, 2, 3, 0, 2, 1, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 3, 1, 7, 6, 2, 3, 2, 4, 2, 6, 7, 3, 0, 7, 2, 2, 1, 0, 2, 2, 2, 2, 8, 4, 3, 2, 8, 5, 7, 2, 2, 0, 2, 0, 2, 2, 2, 0, 7, 3, 6, 2, 0, 2, 2, 8, 2, 1, 2, 0, 2, 7, 8, 7, 4, 2, 2] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 48 finished\n",
      "actions: [1, 2, 2, 2, 2, 3, 8, 1, 4, 2, 2, 6, 2, 3, 4, 2, 2, 7, 2, 6, 0, 2, 2, 8, 6, 6, 0, 6, 2, 2, 3, 5, 1, 3, 2, 8, 5, 2, 2, 1, 5, 0, 1, 2, 2, 8, 2, 2, 2, 2, 1, 2, 7, 5, 7, 2, 3, 2, 4, 2, 7, 0, 5, 2, 2, 2, 2, 2, 8, 2, 3, 8, 4, 5, 8, 6, 2, 1, 3, 5, 3, 2, 2, 8, 1, 2, 8, 2, 2, 0, 5, 2, 2, 0, 8, 4, 2, 7, 6, 5, 2, 2, 2, 0, 2, 6, 1, 0, 2, 3, 2, 5, 2, 4, 7, 5, 2, 2, 5, 2, 7, 7, 2, 2, 4, 2, 8, 3, 1, 2, 2, 2, 4, 8, 6, 2, 2, 2, 0, 3, 8, 8, 2, 6, 2, 4, 3, 1, 1, 3, 2, 2, 2, 2, 1, 3, 2, 2, 2, 5, 2, 3, 2, 2, 2, 0, 2, 6, 2, 7, 6, 2, 4, 2, 3, 0, 2, 3, 1, 0, 0, 4, 0, 2, 1, 2, 2, 8, 0, 2, 2, 5, 8, 1, 2, 3, 2, 2, 2, 0] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 49 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Not enough free spots (#3) to place 1 player and 3 boxes.\n",
      "[SOKOBAN] Retry . . .\n",
      "actions: [2, 5, 8, 4, 2, 2, 2, 2, 1, 8, 2, 2, 1, 0, 2, 0, 2, 3, 2, 1, 2, 2, 2, 2, 1, 0, 6, 2, 1, 0, 7, 2, 6, 8, 2, 2, 2, 6, 8, 2, 2, 8, 2, 2, 5, 2, 7, 2, 7, 0, 2, 6, 2, 6, 4, 2, 2, 2, 6, 2, 4, 7, 8, 2, 8, 5, 2, 1, 2, 2, 2, 2, 1, 2, 2, 0, 2, 7, 2, 2, 5, 0, 3, 1, 2, 4, 2, 2, 2, 8, 6, 2, 3, 3, 8, 2, 2, 6, 5, 2, 7, 2, 7, 1, 4, 2, 0, 3, 5, 5, 1, 0, 7, 2, 1, 2, 5, 2, 4, 8, 5, 7, 2, 4, 2, 3, 1, 0, 2, 2, 1, 1, 2, 8, 2, 2, 4, 2, 2, 5, 4, 2, 0, 4, 2, 2, 7, 8, 1, 4, 2, 2, 2, 2, 7, 2, 2, 8, 1, 1, 2, 5, 3, 2, 0, 2, 0, 0, 7, 2, 8, 4, 5, 2, 2, 8, 2, 2, 5, 5, 3, 3, 1, 6, 2, 6, 3, 3, 2, 1, 7, 2, 0, 2, 2, 3, 3, 2, 2, 6] rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n",
      "global training step 50 finished\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n",
      "[SOKOBAN] Runtime Error/Warning: Not enough free spots (#4) to place 1 player and 3 boxes.\n",
      "[SOKOBAN] Retry . . .\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n",
      "[SOKOBAN] Runtime Error/Warning: Generated Model with score == 0\n",
      "[SOKOBAN] Retry . . .\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-75057161b6a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mglobal_t\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-72-f9b9f53187be>\u001b[0m in \u001b[0;36mtest_model\u001b[1;34m(episodes)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi_episode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Initialize the environment and state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mlast_screen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_screen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mcurrent_screen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_screen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\sokoban_env.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self, second_player, render_mode)\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[0mnum_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_gen_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \u001b[0mnum_boxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_boxes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m                 \u001b[0msecond_player\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msecond_player\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m             )\n\u001b[0;32m    209\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mRuntimeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRuntimeWarning\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mgenerate_room\u001b[1;34m(dim, p_change_directions, num_steps, num_boxes, tries, second_player)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mroom_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroom_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mroom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_mapping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreverse_playing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroom_structure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mroom_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroom_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mreverse_playing\u001b[1;34m(room_state, room_structure, search_depth)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[0mbest_room_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[0mbest_box_mapping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbox_mapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m     \u001b[0mdepth_first_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroom_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_mapping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_pull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mttl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest_room\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_room_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_box_mapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    255\u001b[0m             depth_first_search(room_state_next, room_structure,\n\u001b[0;32m    256\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                last_pull, ttl)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gym_sokoban\\envs\\room_utils.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[1;31m# The state and box mapping  need to be copied to ensure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[1;31m# every action start from a similar state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m             \u001b[0mroom_state_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroom_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m             \u001b[0mbox_mapping_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbox_mapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TRAIN AND TEST LOOP\n",
    "for global_t in range(global_tmax):\n",
    "    train_model(t_max, main_model, global_t)\n",
    "\n",
    "    if global_t % 10 == 0:\n",
    "        test_model(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_action(get_screen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000001D4C545F6C8>\n"
     ]
    }
   ],
   "source": [
    "print(main_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[ 0.1925, -0.2914, -0.0067],\n",
       "           [-0.3249, -0.1618, -0.2433],\n",
       "           [ 0.2535, -0.1491,  0.0276]]],\n",
       " \n",
       " \n",
       "         [[[-0.1695,  0.3124,  0.0666],\n",
       "           [-0.0081,  0.3120, -0.3321],\n",
       "           [ 0.1762, -0.2488, -0.3210]]],\n",
       " \n",
       " \n",
       "         [[[-0.1112, -0.0478,  0.0779],\n",
       "           [-0.2145,  0.0940, -0.0955],\n",
       "           [-0.1347, -0.1201, -0.2593]]],\n",
       " \n",
       " \n",
       "         [[[ 0.2740, -0.1930,  0.2117],\n",
       "           [-0.0659, -0.2719, -0.2950],\n",
       "           [-0.2541,  0.1644, -0.0018]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0949, -0.2039, -0.1859],\n",
       "           [ 0.0058, -0.3058,  0.1397],\n",
       "           [-0.0197,  0.2906, -0.0105]]],\n",
       " \n",
       " \n",
       "         [[[-0.2576,  0.1217,  0.2857],\n",
       "           [-0.2212, -0.2707,  0.2259],\n",
       "           [-0.0015, -0.0568, -0.0387]]],\n",
       " \n",
       " \n",
       "         [[[ 0.2864,  0.1605,  0.1230],\n",
       "           [-0.3046,  0.0346,  0.2702],\n",
       "           [-0.1151, -0.1010, -0.1690]]],\n",
       " \n",
       " \n",
       "         [[[-0.0550,  0.2812, -0.0067],\n",
       "           [-0.1199,  0.1951, -0.2223],\n",
       "           [-0.3101,  0.0913, -0.3035]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1273, -0.1151,  0.1244],\n",
       "           [ 0.2453, -0.1788, -0.2364],\n",
       "           [ 0.2398,  0.0698,  0.1719]]],\n",
       " \n",
       " \n",
       "         [[[-0.1594,  0.3106, -0.0183],\n",
       "           [ 0.0713,  0.2804,  0.1105],\n",
       "           [ 0.3190, -0.1429,  0.2343]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0895,  0.1067,  0.1226],\n",
       "           [-0.0380,  0.2454, -0.2366],\n",
       "           [ 0.1589, -0.2677,  0.1271]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0067,  0.0323, -0.0462],\n",
       "           [ 0.2494,  0.1059, -0.0713],\n",
       "           [-0.3208,  0.2221, -0.2809]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1812, -0.0920,  0.2760],\n",
       "           [-0.3272, -0.3268, -0.1197],\n",
       "           [-0.1464,  0.1036, -0.3057]]],\n",
       " \n",
       " \n",
       "         [[[-0.1446, -0.2665, -0.0683],\n",
       "           [ 0.2142,  0.3246,  0.1488],\n",
       "           [-0.0045,  0.0112,  0.0875]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1984,  0.0630,  0.1869],\n",
       "           [ 0.2831,  0.2834, -0.2593],\n",
       "           [ 0.0681,  0.0311,  0.1963]]],\n",
       " \n",
       " \n",
       "         [[[-0.0877,  0.1492,  0.3112],\n",
       "           [ 0.3196,  0.2004,  0.1524],\n",
       "           [-0.1716, -0.1485,  0.1355]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3294,  0.2013,  0.1122, -0.1129,  0.3190,  0.1123,  0.1803,  0.0892,\n",
       "         -0.0545,  0.0478,  0.0431,  0.1004,  0.2755,  0.0483,  0.0231, -0.2771],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 1.4181e-02, -3.0623e-02, -2.9930e-04],\n",
       "           [ 4.2418e-03, -2.0610e-02,  1.5093e-02],\n",
       "           [-5.3180e-02,  7.9498e-04,  2.3628e-02]],\n",
       " \n",
       "          [[-9.2344e-03,  1.7711e-02,  6.5650e-02],\n",
       "           [-6.4428e-02,  5.7319e-02, -5.9819e-02],\n",
       "           [ 1.7850e-03, -1.0315e-02,  2.2154e-02]],\n",
       " \n",
       "          [[-5.6070e-02, -2.5889e-03, -7.0584e-02],\n",
       "           [ 4.9328e-03,  5.7209e-02, -3.2827e-02],\n",
       "           [-2.7759e-02, -2.0255e-02,  1.4245e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.0770e-02,  7.6299e-02, -5.1038e-02],\n",
       "           [-2.3136e-02,  1.2542e-02, -2.3952e-02],\n",
       "           [ 2.0370e-02,  7.3824e-02, -8.1840e-02]],\n",
       " \n",
       "          [[ 7.2758e-03, -5.5037e-02,  5.3035e-02],\n",
       "           [ 5.7981e-02,  3.7607e-02, -2.4304e-02],\n",
       "           [-5.3225e-03, -7.6215e-02, -2.2583e-02]],\n",
       " \n",
       "          [[ 6.7559e-02,  3.2079e-02, -7.6781e-02],\n",
       "           [ 8.1000e-02,  7.5790e-02,  1.9060e-02],\n",
       "           [ 4.6426e-03, -3.4115e-02,  1.6018e-02]]],\n",
       " \n",
       " \n",
       "         [[[-4.4961e-02,  3.5270e-02,  6.8333e-02],\n",
       "           [ 3.7360e-04, -2.4216e-02,  5.4025e-02],\n",
       "           [-5.6173e-02, -4.0412e-02, -4.7984e-02]],\n",
       " \n",
       "          [[ 3.9091e-02, -3.5415e-02,  6.4289e-02],\n",
       "           [ 2.1731e-02,  5.3539e-03,  2.8629e-02],\n",
       "           [-1.4526e-03, -3.4880e-02,  6.3721e-02]],\n",
       " \n",
       "          [[ 2.2764e-02,  3.6538e-05,  8.2015e-02],\n",
       "           [-6.3531e-02,  1.1283e-03, -4.2484e-03],\n",
       "           [-1.8026e-02,  2.3575e-03,  1.0556e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.2180e-02, -6.8067e-02, -6.5368e-02],\n",
       "           [-6.8159e-02, -5.7005e-02, -1.7362e-02],\n",
       "           [ 7.5266e-02,  5.2456e-02,  5.7046e-02]],\n",
       " \n",
       "          [[ 1.7090e-02,  4.4651e-02,  5.1976e-02],\n",
       "           [-6.0452e-03, -3.8437e-02,  4.1749e-02],\n",
       "           [ 4.7822e-02, -3.5390e-02, -1.2082e-02]],\n",
       " \n",
       "          [[ 6.9161e-02,  6.3275e-02, -1.5774e-02],\n",
       "           [ 1.2288e-02, -2.9937e-02,  3.2410e-02],\n",
       "           [-1.4971e-02, -3.3817e-02, -6.9803e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 5.2443e-02, -1.0720e-02, -3.8492e-02],\n",
       "           [ 7.6119e-02,  1.1969e-02, -4.1654e-02],\n",
       "           [-1.2191e-02, -6.1038e-02, -7.6042e-02]],\n",
       " \n",
       "          [[ 2.2644e-03, -3.3438e-02,  3.5865e-02],\n",
       "           [-5.5095e-02, -1.7524e-02,  3.6402e-02],\n",
       "           [-3.2368e-02,  3.6211e-02, -2.4781e-02]],\n",
       " \n",
       "          [[-4.6137e-02,  4.1418e-02,  1.0018e-02],\n",
       "           [-2.2848e-02, -2.0278e-02, -7.7691e-02],\n",
       "           [ 5.3535e-02,  5.3082e-02, -3.5384e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.7255e-02, -3.2003e-02, -6.1084e-02],\n",
       "           [-7.3801e-02,  5.7163e-02, -7.7169e-02],\n",
       "           [ 9.0349e-03,  8.7129e-03, -3.2958e-02]],\n",
       " \n",
       "          [[ 2.1873e-02,  1.0568e-02,  3.7284e-02],\n",
       "           [-2.7556e-02, -2.7178e-02, -2.6934e-02],\n",
       "           [ 2.0450e-02,  6.5173e-02,  4.0819e-02]],\n",
       " \n",
       "          [[ 4.6772e-02,  8.0429e-03, -5.8663e-02],\n",
       "           [-5.7861e-02,  6.6212e-03, -4.9420e-02],\n",
       "           [-2.0010e-02,  2.8517e-02, -4.1209e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-4.9167e-02, -4.0531e-02, -8.3066e-02],\n",
       "           [-2.5851e-02,  2.1000e-02,  4.2680e-03],\n",
       "           [-4.6557e-02,  6.5163e-02, -7.8672e-02]],\n",
       " \n",
       "          [[ 3.4353e-02,  3.0451e-02,  7.4273e-02],\n",
       "           [-7.7740e-02, -5.4684e-02, -4.5649e-02],\n",
       "           [-1.8325e-03, -6.2925e-03,  6.8334e-02]],\n",
       " \n",
       "          [[-2.6136e-02, -5.7209e-02,  4.9387e-02],\n",
       "           [-1.7593e-02, -4.3066e-02, -2.4419e-02],\n",
       "           [ 6.6578e-02, -2.7561e-02, -6.2339e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.4826e-02,  1.4076e-02,  2.4232e-02],\n",
       "           [-4.2314e-03, -6.3394e-02, -4.7632e-02],\n",
       "           [ 1.2818e-02, -4.2481e-02,  3.4533e-03]],\n",
       " \n",
       "          [[ 7.6445e-02,  1.6427e-02, -2.0846e-02],\n",
       "           [ 6.5083e-02,  6.1036e-02,  3.9856e-02],\n",
       "           [ 3.4757e-02,  2.1165e-02, -1.6434e-02]],\n",
       " \n",
       "          [[-2.3368e-03, -6.1517e-02, -3.0156e-02],\n",
       "           [ 3.8939e-02, -6.0375e-02, -7.9256e-02],\n",
       "           [ 3.9893e-02,  1.7562e-02, -5.3817e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.1579e-02,  2.8129e-02,  2.2063e-02],\n",
       "           [-6.3272e-02,  6.9540e-02, -1.8852e-02],\n",
       "           [-2.4891e-02,  2.2710e-02, -7.7008e-02]],\n",
       " \n",
       "          [[-5.0729e-02,  4.1532e-02, -4.3716e-02],\n",
       "           [-4.1016e-02, -6.7684e-02,  7.6350e-02],\n",
       "           [ 7.0632e-02, -2.4871e-02,  6.1154e-02]],\n",
       " \n",
       "          [[-7.1965e-02, -9.7004e-04,  5.2586e-02],\n",
       "           [ 1.0982e-02, -5.2415e-02, -7.1365e-02],\n",
       "           [ 6.2261e-02, -1.8278e-02, -5.3206e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.2720e-02, -3.0098e-02,  6.7502e-03],\n",
       "           [-1.8162e-02,  2.4732e-02,  6.9952e-02],\n",
       "           [-5.9392e-02, -4.2534e-02, -7.5435e-02]],\n",
       " \n",
       "          [[-4.9642e-02, -1.9579e-02,  8.1416e-02],\n",
       "           [ 7.3661e-02, -4.7668e-02, -8.0101e-02],\n",
       "           [-6.1042e-02,  2.4990e-02, -8.1496e-02]],\n",
       " \n",
       "          [[-3.2915e-03,  6.3448e-03,  2.5534e-02],\n",
       "           [ 5.5108e-02,  1.5499e-02, -2.1400e-02],\n",
       "           [ 3.7709e-03,  1.1998e-02, -7.6347e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.9720e-02, -6.6838e-02, -3.7673e-02],\n",
       "           [-1.4067e-02,  8.1603e-02, -1.4886e-02],\n",
       "           [ 7.7993e-02,  5.1313e-02, -5.6238e-02]],\n",
       " \n",
       "          [[-3.1902e-02,  4.2082e-02,  3.6496e-02],\n",
       "           [ 6.2211e-02, -4.1184e-02,  6.6832e-02],\n",
       "           [ 3.3897e-02, -1.5036e-02,  6.0047e-02]],\n",
       " \n",
       "          [[-6.6112e-02, -4.2113e-02, -7.9167e-02],\n",
       "           [-2.3204e-02, -4.7875e-02, -3.9197e-02],\n",
       "           [ 3.7084e-03,  7.8022e-04,  3.6067e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.9237e-02,  7.7865e-02, -8.0282e-03],\n",
       "           [-5.0175e-02,  7.5026e-02,  4.8758e-02],\n",
       "           [ 4.0386e-02, -4.0522e-02, -2.4972e-02]],\n",
       " \n",
       "          [[-4.8541e-02, -3.4987e-02,  6.9449e-02],\n",
       "           [-7.7712e-03, -1.0623e-02,  2.5027e-02],\n",
       "           [ 5.1472e-02, -7.2773e-02,  5.9666e-02]],\n",
       " \n",
       "          [[ 3.5253e-02,  9.9906e-04,  5.7680e-02],\n",
       "           [-2.4895e-02,  2.1987e-02, -4.9373e-02],\n",
       "           [-6.1900e-02, -6.9581e-02,  6.3541e-02]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0576,  0.0486, -0.0091,  0.0441, -0.0736, -0.0473,  0.0699, -0.0752,\n",
       "         -0.0372,  0.0141, -0.0170,  0.0648,  0.0578, -0.0381, -0.0559,  0.0240,\n",
       "          0.0220,  0.0749,  0.0164, -0.0155,  0.0084, -0.0370,  0.0236,  0.0562,\n",
       "          0.0594,  0.0131, -0.0329, -0.0047, -0.0579, -0.0046,  0.0508, -0.0659],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0584,  0.0318,  0.0011,  ..., -0.0359,  0.0498, -0.0308],\n",
       "         [ 0.0091,  0.0356, -0.0030,  ...,  0.0346, -0.0518, -0.0268],\n",
       "         [-0.0441, -0.0411, -0.0165,  ...,  0.0528, -0.0409,  0.0547],\n",
       "         ...,\n",
       "         [-0.0413,  0.0146, -0.0055,  ...,  0.0193, -0.0195, -0.0453],\n",
       "         [-0.0407,  0.0447, -0.0547,  ...,  0.0214,  0.0380, -0.0425],\n",
       "         [-0.0118, -0.0355,  0.0336,  ...,  0.0147, -0.0212,  0.0030]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 2.5545e-02, -1.9581e-02, -4.6064e-02,  1.0486e-02, -2.8027e-02,\n",
       "         -3.1618e-03, -5.3470e-02, -3.3218e-02, -1.0044e-02, -5.1894e-02,\n",
       "          2.8338e-02, -3.5125e-02, -3.8687e-02,  7.7177e-03, -2.8462e-02,\n",
       "          1.2623e-02,  6.8714e-03, -3.4107e-02,  1.8815e-02, -1.0375e-02,\n",
       "          1.4897e-02,  2.7673e-02, -2.3508e-02,  3.9696e-02, -3.9296e-03,\n",
       "         -3.6061e-02, -1.4502e-03,  3.7328e-03,  1.6239e-02, -2.8299e-02,\n",
       "          3.1201e-02, -1.0203e-02,  7.6786e-03,  1.8186e-02,  4.8840e-02,\n",
       "         -4.7964e-03,  4.2445e-02,  1.8927e-02,  5.0650e-03, -5.5409e-03,\n",
       "          3.3807e-02,  7.7799e-03, -4.7618e-02, -1.0838e-02,  3.9267e-02,\n",
       "         -4.6898e-02,  2.6788e-02,  4.2891e-02,  2.7035e-02,  1.0466e-02,\n",
       "          3.7075e-02,  5.3739e-02,  2.9164e-02, -3.3501e-02, -4.7585e-02,\n",
       "          4.7946e-02, -1.5759e-02,  3.6136e-03,  2.5334e-02, -9.1464e-03,\n",
       "         -4.7499e-02,  4.7814e-02,  6.0329e-03,  3.1423e-02,  4.2031e-02,\n",
       "         -3.8626e-03, -1.2589e-02,  2.8135e-02, -8.2848e-03, -4.9465e-03,\n",
       "         -2.8937e-02,  2.4913e-02,  3.0590e-02,  1.5917e-02, -8.0067e-03,\n",
       "         -5.0932e-02,  5.4018e-02,  2.4973e-02,  5.2527e-02,  2.2412e-02,\n",
       "         -4.5171e-02, -3.5980e-02,  1.0593e-02,  3.1414e-04,  1.9764e-02,\n",
       "          5.6961e-02, -3.2939e-02, -1.8898e-03,  1.9670e-02, -1.5860e-02,\n",
       "          5.7395e-03,  3.3134e-02,  4.3670e-02,  1.0232e-02,  4.2921e-02,\n",
       "          3.7589e-02, -4.6987e-02,  3.9265e-03,  1.6155e-02, -1.0999e-02,\n",
       "          4.1421e-02,  1.4428e-02, -3.1502e-02, -3.0624e-02, -4.9688e-02,\n",
       "          8.1155e-03,  4.7606e-02,  4.4923e-02,  4.1419e-02, -2.9738e-02,\n",
       "         -8.6147e-03, -5.4356e-02, -3.2719e-02, -6.0679e-03, -4.2346e-02,\n",
       "         -4.6870e-02,  2.6972e-02,  1.6907e-02, -4.7805e-02, -8.6413e-03,\n",
       "          1.2894e-02, -3.5805e-02, -1.2907e-02, -2.0678e-02,  2.5541e-02,\n",
       "          1.8965e-02,  5.4334e-02, -1.6140e-02,  5.7888e-03, -4.3428e-02,\n",
       "         -5.6546e-02, -1.8824e-02,  5.3275e-02,  2.4469e-02,  5.2849e-02,\n",
       "         -5.4441e-02, -1.6724e-02,  5.4279e-02, -1.2666e-02, -1.9917e-03,\n",
       "          3.2435e-02,  2.5131e-02, -3.4012e-02, -4.5334e-02, -1.1408e-02,\n",
       "          1.2645e-02,  2.8881e-03, -3.2134e-02,  2.5600e-02,  2.7396e-02,\n",
       "         -5.3157e-02, -5.2608e-02, -5.4666e-02, -3.2056e-02,  1.5987e-02,\n",
       "         -3.6093e-02,  8.1657e-03,  1.7628e-02, -5.1798e-02, -1.8512e-02,\n",
       "         -1.4890e-02, -3.7560e-02, -3.3874e-02, -5.8918e-02,  3.1382e-02,\n",
       "          3.4132e-02,  6.0191e-03,  2.4763e-02, -6.7680e-04, -1.4777e-02,\n",
       "         -4.1145e-02,  4.0817e-02, -4.4289e-02, -5.6901e-02, -2.4304e-03,\n",
       "          5.3686e-02,  8.6746e-03,  4.3281e-03, -2.5910e-02, -3.4868e-02,\n",
       "         -5.4844e-02,  4.3464e-02,  3.8809e-02, -6.7622e-03, -2.6099e-02,\n",
       "          4.4829e-02, -8.2237e-03, -8.0401e-04, -1.4027e-02, -2.0109e-02,\n",
       "         -4.5359e-02,  3.3765e-02,  5.2715e-03, -5.1910e-02, -3.7930e-02,\n",
       "         -1.5798e-02,  4.6891e-02,  2.2587e-02,  1.6617e-02, -1.6696e-02,\n",
       "          2.8799e-02,  4.6833e-02,  1.2480e-02,  1.6927e-02, -2.0606e-02,\n",
       "         -8.0817e-03, -4.2219e-02,  8.1671e-03,  4.5800e-02,  5.1881e-02,\n",
       "         -2.9241e-02,  2.7747e-02, -1.6764e-03, -2.8015e-02,  5.8336e-02,\n",
       "          3.4057e-02,  4.3705e-02, -5.0661e-02, -2.3388e-02, -5.3140e-02,\n",
       "         -2.6120e-02,  4.1801e-02, -7.2013e-03, -3.8160e-02,  2.6066e-02,\n",
       "          3.5045e-02,  5.4152e-02, -5.4280e-02, -1.5251e-02,  3.3352e-02,\n",
       "          4.9600e-02,  2.3717e-02, -1.7895e-02, -1.5440e-02, -2.0952e-02,\n",
       "          5.7009e-02,  4.3493e-02, -2.7523e-02,  8.3133e-03, -2.6851e-02,\n",
       "         -1.5603e-02,  2.9869e-02, -5.3057e-02,  5.3930e-02,  1.9710e-02,\n",
       "         -3.7363e-02, -7.6144e-03,  2.4918e-02, -1.6091e-02,  2.0767e-02,\n",
       "         -1.7904e-02, -2.8208e-02,  4.5079e-02, -4.5908e-02, -3.6584e-02,\n",
       "         -1.3116e-02,  1.7607e-02,  4.9766e-02, -5.5807e-02,  7.3114e-03,\n",
       "          2.9513e-02, -4.2481e-02, -2.1140e-02, -5.1383e-02,  3.2749e-02,\n",
       "         -1.3298e-02,  5.8698e-02,  5.1093e-03,  2.9388e-02,  4.5610e-02,\n",
       "         -6.7578e-03, -2.8743e-02,  2.4821e-03, -5.6775e-02, -7.7382e-05,\n",
       "         -9.9193e-04, -3.4076e-02, -6.9699e-03,  5.3674e-02, -6.9287e-03,\n",
       "          4.8406e-02, -2.0712e-02,  3.5650e-02, -2.4529e-02, -8.9643e-03,\n",
       "         -4.5876e-02, -1.8020e-02, -3.4663e-02], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0130,  0.0576,  0.0264, -0.0287,  0.0563, -0.0258,  0.0388,  0.0334,\n",
       "          -0.0569, -0.0562,  0.0463,  0.0469,  0.0443, -0.0221,  0.0327,  0.0119,\n",
       "           0.0015,  0.0509, -0.0290, -0.0034,  0.0474,  0.0383,  0.0196, -0.0260,\n",
       "          -0.0456, -0.0092,  0.0020,  0.0395, -0.0303,  0.0003, -0.0446,  0.0202,\n",
       "           0.0242,  0.0099,  0.0473, -0.0074, -0.0015,  0.0252, -0.0036, -0.0517,\n",
       "           0.0586,  0.0457,  0.0163,  0.0397, -0.0470, -0.0229,  0.0251,  0.0543,\n",
       "           0.0017,  0.0536, -0.0261, -0.0431,  0.0044,  0.0433,  0.0545, -0.0474,\n",
       "          -0.0273, -0.0247, -0.0292,  0.0099, -0.0345, -0.0040,  0.0306, -0.0405,\n",
       "           0.0292, -0.0441,  0.0192, -0.0440, -0.0440,  0.0371,  0.0079, -0.0287,\n",
       "          -0.0206, -0.0061, -0.0505, -0.0109,  0.0225, -0.0173, -0.0352, -0.0274,\n",
       "           0.0243,  0.0031, -0.0294,  0.0148,  0.0130,  0.0277, -0.0298, -0.0264,\n",
       "           0.0109,  0.0068,  0.0008,  0.0445,  0.0355,  0.0306, -0.0519,  0.0335,\n",
       "           0.0375, -0.0545, -0.0536,  0.0356, -0.0497,  0.0227, -0.0295, -0.0350,\n",
       "          -0.0131,  0.0345, -0.0392, -0.0216,  0.0532,  0.0288,  0.0348,  0.0326,\n",
       "           0.0423, -0.0519, -0.0550,  0.0209, -0.0003, -0.0385,  0.0316,  0.0184,\n",
       "           0.0427,  0.0300, -0.0070,  0.0404,  0.0371, -0.0423,  0.0042, -0.0543,\n",
       "          -0.0101, -0.0320, -0.0570, -0.0550,  0.0463,  0.0164, -0.0483,  0.0512,\n",
       "          -0.0177,  0.0200,  0.0446, -0.0257,  0.0418,  0.0510,  0.0466, -0.0309,\n",
       "           0.0040, -0.0311,  0.0187,  0.0061, -0.0375,  0.0142, -0.0135,  0.0265,\n",
       "          -0.0578, -0.0216,  0.0080,  0.0041, -0.0340, -0.0556, -0.0333, -0.0091,\n",
       "          -0.0462,  0.0470, -0.0030, -0.0164,  0.0388,  0.0015,  0.0115,  0.0195,\n",
       "           0.0381,  0.0295,  0.0331,  0.0146,  0.0345, -0.0265, -0.0073,  0.0142,\n",
       "           0.0199,  0.0451,  0.0247,  0.0266,  0.0392, -0.0210, -0.0215, -0.0115,\n",
       "          -0.0243, -0.0060, -0.0319,  0.0426,  0.0146, -0.0324,  0.0090,  0.0269,\n",
       "          -0.0127,  0.0016,  0.0135,  0.0023,  0.0564,  0.0494, -0.0363, -0.0006,\n",
       "           0.0111, -0.0194,  0.0232,  0.0334,  0.0474,  0.0010, -0.0030, -0.0424,\n",
       "          -0.0399, -0.0577, -0.0132, -0.0514, -0.0420,  0.0349,  0.0133,  0.0432,\n",
       "          -0.0502, -0.0350,  0.0085, -0.0207,  0.0485,  0.0005, -0.0197,  0.0335,\n",
       "           0.0082, -0.0336, -0.0029,  0.0051,  0.0396,  0.0487,  0.0028,  0.0400,\n",
       "          -0.0560,  0.0421,  0.0511, -0.0042,  0.0539,  0.0532,  0.0108,  0.0076,\n",
       "           0.0037, -0.0359,  0.0324,  0.0515,  0.0473, -0.0453, -0.0253, -0.0504,\n",
       "          -0.0175,  0.0193,  0.0116,  0.0504,  0.0291, -0.0246,  0.0175, -0.0350,\n",
       "          -0.0271,  0.0238, -0.0406, -0.0197,  0.0386, -0.0402, -0.0084, -0.0558,\n",
       "          -0.0303,  0.0401, -0.0359,  0.0490,  0.0083,  0.0540,  0.0297, -0.0167,\n",
       "           0.0371, -0.0426,  0.0365,  0.0319,  0.0068,  0.0573, -0.0179, -0.0162,\n",
       "           0.0511,  0.0396, -0.0403, -0.0269,  0.0008, -0.0287, -0.0560,  0.0065]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0369], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0505, -0.0486,  0.0470,  ...,  0.0332, -0.0085,  0.0375],\n",
       "         [-0.0004, -0.0176,  0.0419,  ...,  0.0444, -0.0134, -0.0349],\n",
       "         [-0.0326, -0.0584, -0.0058,  ...,  0.0132, -0.0022, -0.0538],\n",
       "         ...,\n",
       "         [-0.0352, -0.0357, -0.0499,  ...,  0.0568, -0.0041,  0.0515],\n",
       "         [ 0.0507, -0.0504,  0.0157,  ...,  0.0253, -0.0482, -0.0029],\n",
       "         [ 0.0037, -0.0561, -0.0159,  ..., -0.0086, -0.0235,  0.0560]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0569, -0.0320, -0.0186, -0.0546, -0.0512, -0.0089,  0.0240, -0.0086],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(main_model.parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
